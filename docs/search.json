[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\nthis text is a h1 header but does not have the class .title\n\n\nthis is also a level one header (h1)\n\nthis is a title\n\n\nthis will also be red\n\n\nthis will be red"
  },
  {
    "objectID": "blog/2023-10-23-my-first-post/index.html",
    "href": "blog/2023-10-23-my-first-post/index.html",
    "title": "My first blog post",
    "section": "",
    "text": "Hi this is the start of my first blog post trial"
  },
  {
    "objectID": "blog/2023-10-23-my-first-post/index.html#this-is-my-first-section",
    "href": "blog/2023-10-23-my-first-post/index.html#this-is-my-first-section",
    "title": "My first blog post",
    "section": "This is my first section",
    "text": "This is my first section\n:)1"
  },
  {
    "objectID": "blog/2023-10-23-my-first-post/index.html#this-is-my-second-section",
    "href": "blog/2023-10-23-my-first-post/index.html#this-is-my-second-section",
    "title": "My first blog post",
    "section": "This is my second section",
    "text": "This is my second section\n:(2"
  },
  {
    "objectID": "blog/2023-10-23-my-first-post/index.html#references",
    "href": "blog/2023-10-23-my-first-post/index.html#references",
    "title": "My first blog post",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "blog/2023-10-23-my-first-post/index.html#footnotes",
    "href": "blog/2023-10-23-my-first-post/index.html#footnotes",
    "title": "My first blog post",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nthis is my first footnote‚Ü©Ô∏é\nthis is an inline footnote‚Ü©Ô∏é"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "My first blog post\n\n\n\nQuarto\n\n\nMEDS\n\n\nWorkshop\n\n\n\nthis is my short description\n\n\n\nHazel Vaquero\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHouston 2021 Power Outage: Socioeconomic Analysis\n\n\n\nQuarto\n\n\nMEDS\n\n\nWorkshop\n\n\nR\n\n\nGeospatial\n\n\n\nThis is a geospatial anlysis of the 2021 Houston Power Outage that affected millions. I investigate if low income communities were disproportionately affected by the storm.\n\n\n\nHazel Vaquero\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2021 Maricopa County - West Nile Endemic\n\n\n\nR\n\n\nBiostatistics\n\n\nEpidemiology\n\n\n\nStatistical analysis of the West Nile Virus endemic Maricopa County faced in 2021.\n\n\n\nHazel Vaquero\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2021 Thomas Fire Air Quality Index and Fire Scar Analysis\n\n\n\nQuarto\n\n\nMEDS\n\n\nPython\n\n\n\nAn analysis of Santa Barbara‚Äôs 2021 Thomas Fire, visualizing the scar the fire left. As well as analyzing the air quaility level at the time.\n\n\n\nHazel Vaquero\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing NYC Dead Street Trees\n\n\n\n\n\n\nHazel Vaquero\n\n\n\n\n\n\n\n\n\n\n\n\nAccess\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "Welcome!\nMy name is Hazel Vaquero, I am a current graduate students at UC Santa Barbara working towards a masters in Environmental Data Science. My interests include public health, solid waste management, urban sustainability, and coding.\nüè•‚ôªÔ∏èüåÜüå≥üë©üèΩ‚Äçüíª\n\n\nEducation:\nUniversity of California, Santa Barbara (June 2024): MEDS Environmental Data Science\nThe City College of New York(2022): BE Earth System Science and Environmental Engineering"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Welcome!",
    "section": "",
    "text": "University of California, Santa Barbara (June 2024): MEDS Environmental Data Science\nThe City College of New York(2022): BE Earth System Science and Environmental Engineering"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Hazel Vaquero",
    "section": "Experience:",
    "text": "Experience:"
  },
  {
    "objectID": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html",
    "href": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html",
    "title": "2021 Thomas Fire Air Quality Index and Fire Scar Analysis",
    "section": "",
    "text": "In this notebook I analyzed the affects of the Santa Barbara 2017 Thomas Fire. I created a time series showing the Averaged Air Quaility Index(AQI) from 2017 to 2018. As well as creating a raster map of the scar caused by the Thomas Fire.\nAdditional information can be found at my repository"
  },
  {
    "objectID": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#about",
    "href": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#about",
    "title": "2021 Thomas Fire Air Quality Index and Fire Scar Analysis",
    "section": "",
    "text": "In this notebook I analyzed the affects of the Santa Barbara 2017 Thomas Fire. I created a time series showing the Averaged Air Quaility Index(AQI) from 2017 to 2018. As well as creating a raster map of the scar caused by the Thomas Fire.\nAdditional information can be found at my repository"
  },
  {
    "objectID": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#about-the-datasets",
    "href": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#about-the-datasets",
    "title": "Santa Barbara 2021 Thomas Fire AQI and fire scar",
    "section": "About the Datasets",
    "text": "About the Datasets\nIn this notebook we use 3 different data sets.\n\nAQI Time series Data\nEPA‚Äôs Air Quality Data Collected at Outdoor Monitor Stations\nThe first dataset contains information on daily AQI readings across the United States. AQI readings are an indicator that allow the public to understand how polluted their air is. AQI is divided into 6 categories: - Good - Moderate - Unhealthy for Sensetive Groups - Unhealthy - Very Unhealthy - Hazardous\nHigher levels in AQI translate to more pollution present in the atmosphere.\nThis dataset has been download from the EPA‚Äôs Air Quality System (AQS) as a datset. We are interested in 2017 and 2018 Daily AQI by county data. It has 10 columns recording information about the state name, date recorded, AQI, AQI category, and county name. For this analysis we will use the following columns: - County name: County where AQI levels were measured - AQI: air quality measure reported (based on PM2.5 present in the atmosphere)\nAdditional information and metadata for this datset is available in the Airdata Download Files Documentation\n\n\nThomas Fire Scar Data\nCalifornia Fire Perimeter\nThis is a shapefile of California wildfires from 1878 to 2022. The data is updated annually in the spring with the fire perimeters from the previous fire season. As noted by The State of California and the Department of Forestry and Fire Protection this data provides a spatial distribution of the past large fires in California. But, this data is in no way a complete potrayal of the past fires. There are historical data missing, over generalization of big fires, and duplicated fires. Exercise caution when using this shapefile.\nThis shapefile has been downloaded from California Govt State Geoportal. It contains 23 columns recording information on the: year, location, cause, acres, and fire name. For this analysis we will be using the following columns: - Fire name: name of reported fire - Shape Area: Geometry of reported fire, will help with mapping\nAdditional data can be found in the Fire Perimeters Description\nLandsat Data\nThis is a NetCDF file of a raster of Santa Barbara visualizing Santa Barbara. The data was accessed and pre-processed in the Microsoft Planetary Computer. The raster consists of three dimensions: x,y, band. It also contains the following data variables: red, green, blue, nir08(near infared), swir22(short wave). For this analysis we are only interested in the: - x and y dimension - swir22, nir08,red\nAdditional information regarding the Landsat bands can be found at the following USGS websites."
  },
  {
    "objectID": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#final-output",
    "href": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#final-output",
    "title": "2021 Thomas Fire Air Quality Index and Fire Scar Analysis",
    "section": "Final Output",
    "text": "Final Output\nThe final visualization for this notebook are the following figures:\n\nSanta Barbara AQI 2017-2018\n\n\n\nsb_county_aqi.png\n\n\n\nSanta Barbara Thomas Fire 2017\n\n\n\nsb_thomas_fire_2017.png"
  },
  {
    "objectID": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#import-libraries",
    "href": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#import-libraries",
    "title": "2021 Thomas Fire Air Quality Index and Fire Scar Analysis",
    "section": "Import Libraries",
    "text": "Import Libraries\nImport necessary libraries for data wrangling and geospatial analysis\n\n# read in pandas\nimport pandas as pd\n# import matplotlib for colors\nimport matplotlib.pyplot as plt \n\n# import libraries and functions here\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches \n\n## for geospatial analysis\nimport xarray as xr\nimport rioxarray as rioxr\nimport geopandas as gpd"
  },
  {
    "objectID": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#import-data",
    "href": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#import-data",
    "title": "2021 Thomas Fire Air Quality Index and Fire Scar Analysis",
    "section": "Import Data",
    "text": "Import Data\nImport neccessary data.\n\n# read in 2017 Daily AQI by County data\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\")\n\n# read in 2018 Daily AQI by County data\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\")\n                     # read in 2017 and 2018 Daily AQI by County data\naqi_17 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip\")\naqi_18 = pd.read_csv(\"https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip\")\n\n# Import California wildfire data\nwildfires = gpd.read_file('data/California_Fire_Perimeters_2017/California_Fire_Perimeters_2017.shp')\n# Import Landsat\nlandsat = rioxr.open_rasterio(os.path.join(os.getcwd(),'data','landsat8-2018-01-26-sb-simplified.nc'))"
  },
  {
    "objectID": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#prepare-data",
    "href": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#prepare-data",
    "title": "Santa Barbara 2021 Thomas Fire AQI and fire scar",
    "section": "Prepare Data",
    "text": "Prepare Data\n\nAQUI Data Preparation\nWe have two seperate dataframes, we should combine them for our analysis\n\n# \"Glue\" aqi_17 and aqi_18\naqi = pd.concat([aqi_17,aqi_18])\n\nBefore we continue our analysis we should update the column names in a more programmer friendly manner. Update the column names to be lower case and replace the blank space with _.\n\n# Update column by making lower case and replace space with underscore\naqi.columns = aqi.columns.str.lower().str.replace(' ','_')\n\n# View our updates\naqi.head(3)\n\n\n\n\n\n\n\n\nstate_name\ncounty_name\nstate_code\ncounty_code\ndate\naqi\ncategory\ndefining_parameter\ndefining_site\nnumber_of_sites_reporting\n\n\n\n\n0\nAlabama\nBaldwin\n1\n3\n2017-01-01\n21\nGood\nPM2.5\n01-003-0010\n1\n\n\n1\nAlabama\nBaldwin\n1\n3\n2017-01-04\n22\nGood\nPM2.5\n01-003-0010\n1\n\n\n2\nAlabama\nBaldwin\n1\n3\n2017-01-10\n19\nGood\nPM2.5\n01-003-0010\n1\n\n\n\n\n\n\n\nLet us check our dataset type\n\n# check data types of columns\naqi.dtypes\n\nstate_name                   object\ncounty_name                  object\nstate_code                    int64\ncounty_code                   int64\ndate                         object\naqi                           int64\ncategory                     object\ndefining_parameter           object\ndefining_site                object\nnumber_of_sites_reporting     int64\ndtype: object\n\n\nNotice that our date column is an object. Let‚Äôs change that to a datetime64. And update our date column to be the index.\n\n# update date column to be datetime object\naqi = aqi.copy()\naqi.date = pd.to_datetime(aqi.date)\n\nprint(aqi.dtypes)\n\naqi = aqi.set_index(\"date\")\n\n# View index change\nprint(aqi.index)\n\nstate_name                           object\ncounty_name                          object\nstate_code                            int64\ncounty_code                           int64\ndate                         datetime64[ns]\naqi                                   int64\ncategory                             object\ndefining_parameter                   object\ndefining_site                        object\nnumber_of_sites_reporting             int64\ndtype: object\nDatetimeIndex(['2017-01-01', '2017-01-04', '2017-01-10', '2017-01-13',\n               '2017-01-16', '2017-01-19', '2017-01-22', '2017-01-25',\n               '2017-01-28', '2017-01-31',\n               ...\n               '2018-12-22', '2018-12-23', '2018-12-24', '2018-12-25',\n               '2018-12-26', '2018-12-27', '2018-12-28', '2018-12-29',\n               '2018-12-30', '2018-12-31'],\n              dtype='datetime64[ns]', name='date', length=654338, freq=None)\n\n\n\n\nLandsat Data Preparation\nFirst we can take a quick look at our landsat\n\n# View landsat\nlandsat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:      (y: 731, x: 870, band: 1)\nCoordinates:\n  * y            (y) float64 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n  * x            (x) float64 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * band         (band) int64 1\n    spatial_ref  int64 0\nData variables:\n    red          (band, y, x) float64 ...\n    green        (band, y, x) float64 ...\n    blue         (band, y, x) float64 ...\n    nir08        (band, y, x) float64 ...\n    swir22       (band, y, x) float64 ...xarray.DatasetDimensions:y: 731x: 870band: 1Coordinates: (4)y(y)float643.952e+06 3.952e+06 ... 3.755e+06axis :Ycrs :EPSG:32611long_name :y coordinate of projectionresolution :-30standard_name :projection_y_coordinateunits :metre_FillValue :nanarray([3952395., 3952125., 3951855., ..., 3755835., 3755565., 3755295.])x(x)float641.213e+05 1.216e+05 ... 3.559e+05axis :Xcrs :EPSG:32611long_name :x coordinate of projectionresolution :30standard_name :projection_x_coordinateunits :metre_FillValue :nanarray([121305., 121575., 121845., ..., 355395., 355665., 355935.])band(band)int641array([1])spatial_ref()int640crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :121170.0 270.0 0.0 3952530.0 0.0 -270.0array(0)Data variables: (5)red(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]green(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]blue(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]nir08(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]swir22(band, y, x)float64...add_offset :0.0coordinates :timescale_factor :1.0_FillValue :0.0[635970 values with dtype=float64]Attributes: (0)\n\n\nOne issue we see is that we have an extra dimension band that is not needed. Let‚Äôs remove it!\n\n# There are 3 dimensions in Landsat let's drop band\n# original dimensions and coordinates\nprint(f\"Original dimensions: {landsat.dims} \\n{landsat.coords}\")\n\n# remove length 1 dimension (band)\nlandsat = landsat.squeeze()\nprint(landsat.dims, landsat.coords, '\\n')\n\n# remove coordinates associated to band\nlandsat = landsat.drop('band')\nprint(landsat.dims, landsat.coords, '\\n')\n\nOriginal dimensions: Frozen({'y': 731, 'x': 870, 'band': 1}) \nCoordinates:\n  * y            (y) float64 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n  * x            (x) float64 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n  * band         (band) int64 1\n    spatial_ref  int64 0\nFrozen({'y': 731, 'x': 870}) Coordinates:\n  * y            (y) float64 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n  * x            (x) float64 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n    band         int64 1\n    spatial_ref  int64 0 \n\nFrozen({'y': 731, 'x': 870}) Coordinates:\n  * y            (y) float64 3.952e+06 3.952e+06 ... 3.756e+06 3.755e+06\n  * x            (x) float64 1.213e+05 1.216e+05 ... 3.557e+05 3.559e+05\n    spatial_ref  int64 0 \n\n\n\n\n\nWildfire Data Preparation\nLets explore our Wildfire shapefile and view it‚Äôs attributes before data preparation.\n\n# View dataframe\nwildfires.head(3)\n\n\n\n\n\n\n\n\nindex\nOBJECTID\nYEAR_\nSTATE\nAGENCY\nUNIT_ID\nFIRE_NAME\nINC_NUM\nALARM_DATE\nCONT_DATE\n...\nGIS_ACRES\nCOMMENTS\nCOMPLEX_NA\nCOMPLEX_IN\nIRWINID\nFIRE_NUM\nDECADES\nSHAPE_Leng\nSHAPE_Area\ngeometry\n\n\n\n\n0\n19836\n41429\n2017\nCA\nCCO\nVNC\nBROOK\n00042450\n2017-05-23\n2017-05-24\n...\n10.043819\nper walked track\nNone\nNone\nNone\nNone\n2010\n1246.055781\n59473.666651\nPOLYGON ((-13229812.974 4046876.486, -13229786...\n\n\n1\n19837\n41430\n2017\nCA\nCCO\nVNC\nPACIFIC\n00075307\n2017-09-09\n2017-09-09\n...\n1.190109\nFinal Walked track. Small spot to the north east\nNone\nNone\nNone\nNone\n2010\n561.418202\n7081.369481\nPOLYGON ((-13286872.985 4074523.355, -13286895...\n\n\n2\n19838\n41431\n2017\nCA\nCCO\nVNC\nGRADE\n00054660\n2017-07-04\n2017-07-05\n...\n47.194027\nNone\nNone\nNone\nNone\nNone\n2010\n2587.259697\n279911.825212\nPOLYGON ((-13244637.580 4056332.530, -13244620...\n\n\n\n\n3 rows √ó 23 columns\n\n\n\nLets update the column names to lowercase\n\n# Make column names lowercase\nwildfires.columns = wildfires.columns.str.lower()\n\n# View our update\nwildfires.columns\n\nIndex(['index', 'objectid', 'year_', 'state', 'agency', 'unit_id', 'fire_name',\n       'inc_num', 'alarm_date', 'cont_date', 'cause', 'c_method', 'objective',\n       'gis_acres', 'comments', 'complex_na', 'complex_in', 'irwinid',\n       'fire_num', 'decades', 'shape_leng', 'shape_area', 'geometry'],\n      dtype='object')\n\n\nA necessary step for plotting the Landsat data and Wildfire data is to make sure they are projected on the same CRS. Let‚Äôs check if their CRS are the same, if not let us update them.\n\n# Check Wildfires original CRS\nprint(f\"Original CRS check: {wildfires.crs == landsat.rio.crs}\")\n\n#Update wildfire CRS to match Landsar CRS\nwildfires = wildfires.to_crs(landsat.rio.crs)\n\n# Check update\nprint(f\"Updated CRS check: {wildfires.crs == landsat.rio.crs}\")\n\nOriginal CRS check: False\nUpdated CRS check: True"
  },
  {
    "objectID": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#data-selection",
    "href": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#data-selection",
    "title": "2021 Thomas Fire Air Quality Index and Fire Scar Analysis",
    "section": "Data Selection",
    "text": "Data Selection\n\nSanta Barbara\nOur current dataframe includes all Counties in the United States. But, we are only interested in Santa Barbara. Let‚Äôs filter our dataframe to Santa Barbara County and drop unecessary columns.\n\n# Select Santa Barbara\naqi_sb = aqi[aqi.county_name == \"Santa Barbara\"]\n\n# Check that we only filtered for Santa Barbara by unique county_names\naqi_sb.county_name.unique()\n\n# remove state_name, county_name, state_code and county_code columns\naqi_sb = aqi_sb.drop(columns = ['state_name','county_name','state_code','county_code'])\n\n\n\nWildfire\nOur interest is only on the Thomas fire, let us filter our data to only include it.\n\n# We are interested in the THOMAS FIRE\n# Filter dataset to THOMAS FIRE\nwildfires = wildfires[wildfires.fire_name == 'THOMAS']"
  },
  {
    "objectID": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#geographic-context",
    "href": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#geographic-context",
    "title": "2021 Thomas Fire Air Quality Index and Fire Scar Analysis",
    "section": "Geographic Context",
    "text": "Geographic Context\nFor context, let see where Santa Barbara county is relative to California\n\n\n\nsb_ca.png"
  },
  {
    "objectID": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#data-visualization",
    "href": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#data-visualization",
    "title": "2021 Thomas Fire Air Quality Index and Fire Scar Analysis",
    "section": "Data Visualization",
    "text": "Data Visualization\n\nTime Series\nTo calculate the trend of AQI values we conduct a 5-day rolling average.\n\n# Create a new column with mean AQI over a 5-day rolling average.\n#aqi_sb[\"five_day_average\"] = aqi_sb.aqi.rolling(\"5D\").mean()\n\naqi_sb[\"five_day_average\"] = aqi_sb.aqi.rolling(\"5D\").mean()\n\nNow we can make a line plot of our time series! Let us compare both the daily AQI and 5-day moving average.\n\n# define colors for plot\ncolors = ['thistle','firebrick']\n\n# ------ Plot figure -----------------------------------------------------------------\n# line plot of daily AQI and the 5-day average \naqi_sb.plot(y = ['aqi','five_day_average'], # setting y as AQI and 5-day average AQI\n           xlabel = \"Date\", # x-axis label\n           ylabel = \"PM2.5 (Œºm)\", #y-axis label\n           title = \"Daily AQI and 5-day average AQI for Santa Barbara\", # title \n           color = colors) #setting colors for lines\n\n# -----Save Figure-----------------------------------------------------------------------\nplt.savefig('images/sb_county_aqi.png',bbox_inches = 'tight',dpi = 100)\nplt.show()\n\n\n\n\nWe see that Daily AQI peaks around December which is on par with when the Thomas Fire (December 4 - March 22) occured. An interesting thing to note is that the peak AQI was reached right at the start of the fire and eventually returned to the average AQI after January, even though the fire did not stop till March.\n\n\nMap of Fire Scar\nI can now map the Thomas Fire scar on top of the Santa Barbara raster.\n\n# Plot Wildfire and Landsat data together\nfig, ax = plt.subplots()\n\n# ---Landsat Map------------------------------------------------------------------------------------------------------------\n# Here we are plotting with false color image by plotting the short-waved infared (swir22), near-infared, and red variable\n# False color imaging allows us to differentiate the Thomas fire scar from the rest of the Santa Barbara area\nlandsat[['swir22','nir08','red']].to_array().plot.imshow(ax=ax,robust = True)\nax.set_facecolor('white')\n\n#---Thomas Fire Layer-------------------------------------------------------------------------------------------------------\nwildfires.plot(ax=ax, color = 'none', edgecolor = \"yellow\", linewidth = 1)\nwildfires_patch = mpatches.Patch(color = 'yellow',\n                                label = 'Thomas fire perimeter')\n\n# ---Legend-----------------------------------------------------------------------------------------------------------------\nplt.title(\"Fire scar of Thomas Fire, 2017\") # title\nax.legend(handles = [wildfires_patch], frameon = False, loc = \"upper right\", labelcolor = \"white\")\n\n# ------Save Image----------------------------------------------------------------------------------------------------------\nplt.savefig('images/sb_thomas_fire_2017.png',bbox_inches = 'tight',dpi = 100)\nplt.show() \n\n\n\n\nBased on the map we can see that Thomas Fire heavily affected Ventura and Ojai.\nCode for making Geographic context\n\n{\n    \"tags\": [\n        \"hide-cell\",\n    ]\n}\n\n#--------- Import California boundary -----------------------------------------\ncalifornia = gpd.read_file(\"data/california_boundary/CA_State_TIGER2016.shp\")\ncali_counties = gpd.read_file(\"data/california_counties_boundaries/CA_Counties_TIGER2016.shp\")\n\n# -------Filter to Santa Barbara ----------------------------------------------\nsanta_barbara = cali_counties[cali_counties.NAME == \"Santa Barbara\"]\n# ---------Create Map----------------------------------------------------------\nfig, ax = plt.subplots()\nax.axis('off')\n\nax.set_title(\"Santa Barbara County Location in California\")\n\ncalifornia.plot(ax=ax,color = 'bisque')\nsanta_barbara.plot(ax=ax, color = 'plum', edgecolor = \"black\")\nsb_patch = mpatches.Patch(color = \"plum\",\n                         label = 'Santa Barbara')\nax.legend(handles = [sb_patch], frameon = False, loc = \"lower left\", labelcolor = \"black\")\n\nplt.savefig('../Santa-Barbara-Thomas-Fire/images/sb_ca.png',bbox_inches = 'tight',dpi = 100)"
  },
  {
    "objectID": "blog/STAC-search.html",
    "href": "blog/STAC-search.html",
    "title": "Access",
    "section": "",
    "text": "import numpy as np\nimport geopandas as gpd\nimport rioxarray as rioxr\nimport matplotlib.pyplot as plt\n\nfrom shapely.geometry import Polygon\n\n# Used to access STAC catalogs\nfrom pystac_client import Client\n# Used to sign items from the MPC STAC catalog\nimport planetary_computer\n\n# other libraries for nice outputs\nfrom IPython.display import Image\nmpc_env\nWe use the Client function from the pystac_client package to acess the catalog\n# acess catalog\n\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\nThe modifier parameter is needed to access the data in the MPC catalog."
  },
  {
    "objectID": "blog/STAC-search.html#exploration",
    "href": "blog/STAC-search.html#exploration",
    "title": "Access",
    "section": "Exploration",
    "text": "Exploration\nLet‚Äôs check out some of the catalog‚Äôs metadata:\n\n# metadata from the catalog\nprint('Title:', catalog.title)\nprint('Description:',catalog.description)\n\nTitle: Microsoft Planetary Computer STAC API\nDescription: Searchable spatiotemporal metadata describing Earth science datasets hosted by the Microsoft Planetary Computer\n\n\nWe can access the catalog collection by using the get_collections() method\n\ncatalog.get_collections() # Nothing happens\n# Generator objects are lazy objects you need to ask it to print it out\n\n&lt;generator object Client.get_collections at 0x7fd1394efbc0&gt;\n\n\nNotice the output of get_collections() is a generator.\nThis is a special kind of lazy object in Python over which you can loop over like a list. Unlike a list, the items in a generator do not exist in memory until you explicitely iterate over them or convert them to a list. Let‚Äôs try getting the collections from the catalog again:\n\n# get collections and print their names\ncollections = list(catalog.get_collections())\nprint('Number of Collections:', len(collections))\nprint('Collection IDs:')\n\nfor collection in collections:\n    print('-',collection.id)\n\nNumber of Collections: 122\nCollection IDs:\n- daymet-annual-pr\n- daymet-daily-hi\n- 3dep-seamless\n- 3dep-lidar-dsm\n- fia\n- sentinel-1-rtc\n- gridmet\n- daymet-annual-na\n- daymet-monthly-na\n- daymet-annual-hi\n- daymet-monthly-hi\n- daymet-monthly-pr\n- gnatsgo-tables\n- hgb\n- cop-dem-glo-30\n- cop-dem-glo-90\n- goes-cmi\n- terraclimate\n- nasa-nex-gddp-cmip6\n- gpm-imerg-hhr\n- gnatsgo-rasters\n- 3dep-lidar-hag\n- 3dep-lidar-intensity\n- 3dep-lidar-pointsourceid\n- mtbs\n- noaa-c-cap\n- 3dep-lidar-copc\n- modis-64A1-061\n- alos-fnf-mosaic\n- 3dep-lidar-returns\n- mobi\n- landsat-c2-l2\n- era5-pds\n- chloris-biomass\n- kaza-hydroforecast\n- planet-nicfi-analytic\n- modis-17A2H-061\n- modis-11A2-061\n- daymet-daily-pr\n- 3dep-lidar-dtm-native\n- 3dep-lidar-classification\n- 3dep-lidar-dtm\n- gap\n- modis-17A2HGF-061\n- planet-nicfi-visual\n- gbif\n- modis-17A3HGF-061\n- modis-09A1-061\n- alos-dem\n- alos-palsar-mosaic\n- deltares-water-availability\n- modis-16A3GF-061\n- modis-21A2-061\n- us-census\n- jrc-gsw\n- deltares-floods\n- modis-43A4-061\n- modis-09Q1-061\n- modis-14A1-061\n- hrea\n- modis-13Q1-061\n- modis-14A2-061\n- sentinel-2-l2a\n- modis-15A2H-061\n- modis-11A1-061\n- modis-15A3H-061\n- modis-13A1-061\n- daymet-daily-na\n- nrcan-landcover\n- modis-10A2-061\n- ecmwf-forecast\n- noaa-mrms-qpe-24h-pass2\n- sentinel-1-grd\n- nasadem\n- io-lulc\n- landsat-c2-l1\n- drcog-lulc\n- chesapeake-lc-7\n- chesapeake-lc-13\n- chesapeake-lu\n- noaa-mrms-qpe-1h-pass1\n- noaa-mrms-qpe-1h-pass2\n- noaa-nclimgrid-monthly\n- goes-glm\n- usda-cdl\n- eclipse\n- esa-cci-lc\n- esa-cci-lc-netcdf\n- fws-nwi\n- usgs-lcmap-conus-v13\n- usgs-lcmap-hawaii-v10\n- noaa-climate-normals-tabular\n- noaa-climate-normals-netcdf\n- noaa-climate-normals-gridded\n- aster-l1t\n- cil-gdpcir-cc-by-sa\n- io-lulc-9-class\n- io-biodiversity\n- naip\n- noaa-cdr-sea-surface-temperature-whoi\n- noaa-cdr-ocean-heat-content\n- cil-gdpcir-cc0\n- cil-gdpcir-cc-by\n- noaa-cdr-sea-surface-temperature-whoi-netcdf\n- noaa-cdr-sea-surface-temperature-optimum-interpolation\n- modis-10A1-061\n- sentinel-5p-l2-netcdf\n- sentinel-3-olci-wfr-l2-netcdf\n- noaa-cdr-ocean-heat-content-netcdf\n- sentinel-3-synergy-aod-l2-netcdf\n- sentinel-3-synergy-v10-l2-netcdf\n- sentinel-3-olci-lfr-l2-netcdf\n- sentinel-3-sral-lan-l2-netcdf\n- sentinel-3-slstr-lst-l2-netcdf\n- sentinel-3-slstr-wst-l2-netcdf\n- sentinel-3-sral-wat-l2-netcdf\n- ms-buildings\n- sentinel-3-slstr-frp-l2-netcdf\n- sentinel-3-synergy-syn-l2-netcdf\n- sentinel-3-synergy-vgp-l2-netcdf\n- sentinel-3-synergy-vg1-l2-netcdf\n- esa-worldcover"
  },
  {
    "objectID": "blog/STAC-search.html#collection",
    "href": "blog/STAC-search.html#collection",
    "title": "Access",
    "section": "Collection",
    "text": "Collection\nWe can select a single collection for exploration using the get_child() method for the catalog and the collection id as the parameter:\n\nnaip_collection = catalog.get_child('naip')\nnaip_collection\n\n\n\n\n    \n    \n    \n        \n            \n                \n                    CollectionClient: naip\n                \n            \n            \n\n\n\n\n\n\nid: naip\n\n\ntitle: NAIP: National Agriculture Imagery Program\n\n\ndescription: The [National Agriculture Imagery Program](https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/) (NAIP) provides U.S.-wide, high-resolution aerial imagery, with four spectral bands (R, G, B, IR). NAIP is administered by the [Aerial Field Photography Office](https://www.fsa.usda.gov/programs-and-services/aerial-photography/) (AFPO) within the [US Department of Agriculture](https://www.usda.gov/) (USDA). Data are captured at least once every three years for each state. This dataset represents NAIP data from 2010-present, in [cloud-optimized GeoTIFF](https://www.cogeo.org/) format.\n\n\nproviders:\n\n\nUSDA Farm Service Agency (producer, licensor)\n\n\nEsri (processor)\n\n\nMicrosoft (host, processor)\n\n\n\n\ntype: Collection\n\n\nitem_assets: {'image': {'type': 'image/tiff; application=geotiff; profile=cloud-optimized', 'roles': ['data'], 'title': 'RGBIR COG tile', 'eo:bands': [{'name': 'Red', 'common_name': 'red'}, {'name': 'Green', 'common_name': 'green'}, {'name': 'Blue', 'common_name': 'blue'}, {'name': 'NIR', 'common_name': 'nir', 'description': 'near-infrared'}]}, 'metadata': {'type': 'text/plain', 'roles': ['metadata'], 'title': 'FGDC Metdata'}, 'thumbnail': {'type': 'image/jpeg', 'roles': ['thumbnail'], 'title': 'Thumbnail'}}\n\n\nmsft:region: westeurope\n\n\nmsft:container: naip\n\n\nmsft:storage_account: naipeuwest\n\n\nmsft:short_description: NAIP provides US-wide, high-resolution aerial imagery. This dataset includes NAIP images from 2010 to the present.\n\n\n\n\nSTAC Extensions\n\n\n\nhttps://stac-extensions.github.io/item-assets/v1.0.0/schema.json\n\n\nhttps://stac-extensions.github.io/table/v1.2.0/schema.json\n\n\n\n\n\nItems\nOnly the first item shown\n\n\n\n\n\nItem: hi_m_2015561_sw_05_060_20211226_20220909\n\n\n\nid: hi_m_2015561_sw_05_060_20211226_20220909\n\n\nbbox: [-155.502923, 19.997278, -155.434587, 20.065225]\n\n\ngsd: 0.6\n\n\ndatetime: 2021-12-26T16:00:00Z\n\n\nnaip:year: 2021\n\n\nproj:bbox: [238224.0, 2213136.0, 245268.0, 2220558.0]\n\n\nproj:epsg: 26905\n\n\nproviders: [{'url': 'https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/', 'name': 'USDA Farm Service Agency', 'roles': ['producer', 'licensor']}]\n\n\nnaip:state: hi\n\n\nproj:shape: [12370, 11740]\n\n\nproj:transform: [0.6, 0.0, 238224.0, 0.0, -0.6, 2220558.0, 0.0, 0.0, 1.0]\n\n\n\n\nSTAC Extensions\n\n\n\nhttps://stac-extensions.github.io/eo/v1.0.0/schema.json\n\n\nhttps://stac-extensions.github.io/projection/v1.0.0/schema.json\n\n\n\n\n\nAssets\n\n\n\n\n\nAsset: RGBIR COG tile\n\n\n\nhref: https://naipeuwest.blob.core.windows.net/naip/v002/hi/2021/hi_060cm_2021/20155/61/m_2015561_sw_05_060_20211226_20220909.tif\n\n\ntype: image/tiff; application=geotiff; profile=cloud-optimized\n\n\ntitle: RGBIR COG tile\n\n\nroles: ['data']\n\n\nowner: hi_m_2015561_sw_05_060_20211226_20220909\n\n\neo:bands: [{'name': 'Red', 'common_name': 'red'}, {'name': 'Green', 'common_name': 'green'}, {'name': 'Blue', 'common_name': 'blue'}, {'name': 'NIR', 'common_name': 'nir', 'description': 'near-infrared'}]\n\n\n\n\n\n\n\n\n\n\nAsset: Thumbnail\n\n\n\nhref: https://naipeuwest.blob.core.windows.net/naip/v002/hi/2021/hi_060cm_2021/20155/m_2015561_sw_05_060_20211226_20220909.200.jpg\n\n\ntype: image/jpeg\n\n\ntitle: Thumbnail\n\n\nroles: ['thumbnail']\n\n\nowner: hi_m_2015561_sw_05_060_20211226_20220909\n\n\n\n\n\n\n\n\n\n\nAsset: TileJSON with default rendering\n\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=hi_m_2015561_sw_05_060_20211226_20220909&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\n\n\ntype: application/json\n\n\ntitle: TileJSON with default rendering\n\n\nroles: ['tiles']\n\n\nowner: hi_m_2015561_sw_05_060_20211226_20220909\n\n\n\n\n\n\n\n\n\n\nAsset: Rendered preview\n\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=hi_m_2015561_sw_05_060_20211226_20220909&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\n\n\ntype: image/png\n\n\ntitle: Rendered preview\n\n\nroles: ['overview']\n\n\nowner: hi_m_2015561_sw_05_060_20211226_20220909\n\n\nrel: preview\n\n\n\n\n\n\n\nLinks\n\n\n\n\n\nLink:\n\n\n\nrel: collection\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\n\n\ntype: application/json\n\n\n\n\n\n\n\n\n\n\nLink:\n\n\n\nrel: parent\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\n\n\ntype: application/json\n\n\n\n\n\n\n\n\n\n\nLink: Microsoft Planetary Computer STAC API\n\n\n\nrel: root\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/\n\n\ntype: application/json\n\n\ntitle: Microsoft Planetary Computer STAC API\n\n\n\n\n\n\n\n\n\n\nLink:\n\n\n\nrel: self\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items/hi_m_2015561_sw_05_060_20211226_20220909\n\n\ntype: application/geo+json\n\n\n\n\n\n\n\n\n\n\nLink: Map of item\n\n\n\nrel: preview\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=naip&item=hi_m_2015561_sw_05_060_20211226_20220909\n\n\ntype: text/html\n\n\ntitle: Map of item\n\n\n\n\n\n\n\n\n\n\nLinks\n\n\n\n\n\nLink:\n\n\n\nrel: items\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items\n\n\ntype: application/geo+json\n\n\n\n\n\n\n\n\n\n\nLink: Microsoft Planetary Computer STAC API\n\n\n\nrel: root\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/\n\n\ntype: application/json\n\n\ntitle: Microsoft Planetary Computer STAC API\n\n\n\n\n\n\n\n\n\n\nLink: Public Domain\n\n\n\nrel: license\n\n\nhref: https://www.fsa.usda.gov/help/policies-and-links/\n\n\ntitle: Public Domain\n\n\n\n\n\n\n\n\n\n\nLink: Human readable dataset overview and reference\n\n\n\nrel: describedby\n\n\nhref: https://planetarycomputer.microsoft.com/dataset/naip\n\n\ntype: text/html\n\n\ntitle: Human readable dataset overview and reference\n\n\n\n\n\n\n\n\n\n\nLink:\n\n\n\nrel: self\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\n\n\ntype: application/json\n\n\n\n\n\n\n\n\n\n\nLink: Microsoft Planetary Computer STAC API\n\n\n\nrel: parent\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1\n\n\ntype: application/json\n\n\ntitle: Microsoft Planetary Computer STAC API\n\n\n\n\n\n\n\nAssets\n\n\n\n\n\nAsset: NAIP thumbnail\n\n\n\nhref: https://ai4edatasetspublicassets.blob.core.windows.net/assets/pc_thumbnails/naip.png\n\n\ntype: image/png\n\n\ntitle: NAIP thumbnail\n\n\nroles: ['thumbnail']\n\n\nowner: naip\n\n\n\n\n\n\n\n\n\n\nAsset: GeoParquet STAC items\n\n\n\nhref: abfs://items/naip.parquet\n\n\ntype: application/x-parquet\n\n\ntitle: GeoParquet STAC items\n\n\ndescription: Snapshot of the collection's STAC items exported to GeoParquet format.\n\n\nroles: ['stac-items']\n\n\nowner: naip\n\n\nmsft:partition_info: {'is_partitioned': True, 'partition_frequency': 'AS'}\n\n\ntable:storage_options: {'account_name': 'pcstacitems'}"
  },
  {
    "objectID": "blog/STAC-search.html#catalog-search",
    "href": "blog/STAC-search.html#catalog-search",
    "title": "Access",
    "section": "Catalog Search",
    "text": "Catalog Search\nWe can narrow the search withing the catalog by specifying a time range, an area of interest, and the collection name. The simplest ways to define the area of interest to look for data in the catalog are:\n\na GeoJSON-type dictionary with the coordinates of the bounding box,\nas a list [xmin, ymin, xmax, ymax] with the coordinate values defining the four corners of the bounding box.\n\nIn this lesson we will look for the NAIP scenes over Santa Barbara from 2018 to 2023. We‚Äôll use the GeoJSON method to define the area of interest:\n\n# temporal range of interest\ntime_range = \"2018-01-01/2023-01-01\"\n\n#NCEAS bounding box\n# NCEAS bounding box (as a GeoJSON)\n\n# Dictionary and the second key has a list of tupples\nbbox = {\n    \"type\": \"Polygon\",\n    \"coordinates\":[\n        [\n            [-119.70608227128903, 34.426300194372274],\n            [-119.70608227128903, 34.42041139020533],\n            [-119.6967885126002, 34.42041139020533],\n            [-119.6967885126002, 34.426300194372274],\n            [-119.70608227128903, 34.426300194372274]\n        ]\n    ],\n}\n\n# catalog search\nsearch = catalog.search(\n    collections=['naip'],\n    intersects=bbox,\n    datetime=time_range)\nsearch\n\n&lt;pystac_client.item_search.ItemSearch at 0x7fd13313b650&gt;\n\n\nTo get the items found in the search (or check if there were any matches in the search) we use the item_collection() method:\n\nitems = search.item_collection()\nlen(items)\n\n2\n\n\nThis output tells us there were two items in the catalog that matched our search!\n\nitems\n# Assets in the items you see the url for getting the data\n\n\n\n\n    \n    \n    \n        \n            \n                \n                    ItemCollection\n                \n            \n            \n\nItems\n\n\n\n\n\nItem: ca_m_3411935_sw_11_060_20200521\n\n\n\nid: ca_m_3411935_sw_11_060_20200521\n\n\nbbox: [-119.754272, 34.371741, -119.683292, 34.440724]\n\n\ngsd: 0.6\n\n\ndatetime: 2020-05-21T00:00:00Z\n\n\nnaip:year: 2020\n\n\nproj:bbox: [246930.0, 3806808.0, 253260.0, 3814296.0]\n\n\nproj:epsg: 26911\n\n\nnaip:state: ca\n\n\nproj:shape: [12480, 10550]\n\n\nproj:transform: [0.6, 0.0, 246930.0, 0.0, -0.6, 3814296.0, 0.0, 0.0, 1.0]\n\n\n\n\nSTAC Extensions\n\n\n\nhttps://stac-extensions.github.io/eo/v1.0.0/schema.json\n\n\nhttps://stac-extensions.github.io/projection/v1.0.0/schema.json\n\n\n\n\n\nAssets\n\n\n\n\n\nAsset: RGBIR COG tile\n\n\n\nhref: https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.tif?st=2023-11-26T21%3A18%3A54Z&se=2023-12-04T21%3A18%3A54Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-27T21%3A18%3A53Z&ske=2023-12-04T21%3A18%3A53Z&sks=b&skv=2021-06-08&sig=yOs1LiWCX0hM/gh73pDEEA2ae6DeSdqwRWLQBSvyu3Q%3D\n\n\ntype: image/tiff; application=geotiff; profile=cloud-optimized\n\n\ntitle: RGBIR COG tile\n\n\nroles: ['data']\n\n\nowner: ca_m_3411935_sw_11_060_20200521\n\n\neo:bands: [{'name': 'Red', 'common_name': 'red'}, {'name': 'Green', 'common_name': 'green'}, {'name': 'Blue', 'common_name': 'blue'}, {'name': 'NIR', 'common_name': 'nir', 'description': 'near-infrared'}]\n\n\n\n\n\n\n\n\n\n\nAsset: Thumbnail\n\n\n\nhref: https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.200.jpg?st=2023-11-26T21%3A18%3A54Z&se=2023-12-04T21%3A18%3A54Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-27T21%3A18%3A53Z&ske=2023-12-04T21%3A18%3A53Z&sks=b&skv=2021-06-08&sig=yOs1LiWCX0hM/gh73pDEEA2ae6DeSdqwRWLQBSvyu3Q%3D\n\n\ntype: image/jpeg\n\n\ntitle: Thumbnail\n\n\nroles: ['thumbnail']\n\n\nowner: ca_m_3411935_sw_11_060_20200521\n\n\n\n\n\n\n\n\n\n\nAsset: TileJSON with default rendering\n\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\n\n\ntype: application/json\n\n\ntitle: TileJSON with default rendering\n\n\nroles: ['tiles']\n\n\nowner: ca_m_3411935_sw_11_060_20200521\n\n\n\n\n\n\n\n\n\n\nAsset: Rendered preview\n\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\n\n\ntype: image/png\n\n\ntitle: Rendered preview\n\n\nroles: ['overview']\n\n\nowner: ca_m_3411935_sw_11_060_20200521\n\n\nrel: preview\n\n\n\n\n\n\n\nLinks\n\n\n\n\n\nLink:\n\n\n\nrel: collection\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\n\n\ntype: application/json\n\n\n\n\n\n\n\n\n\n\nLink:\n\n\n\nrel: parent\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\n\n\ntype: application/json\n\n\n\n\n\n\n\n\n\n\nLink: Microsoft Planetary Computer STAC API\n\n\n\nrel: root\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1\n\n\ntype: application/json\n\n\ntitle: Microsoft Planetary Computer STAC API\n\n\n\n\n\n\n\n\n\n\nLink:\n\n\n\nrel: self\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items/ca_m_3411935_sw_11_060_20200521\n\n\ntype: application/geo+json\n\n\n\n\n\n\n\n\n\n\nLink: Map of item\n\n\n\nrel: preview\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=naip&item=ca_m_3411935_sw_11_060_20200521\n\n\ntype: text/html\n\n\ntitle: Map of item\n\n\n\n\n\n\n\n\n\n\n\n\n\nItem: ca_m_3411935_sw_11_060_20180724_20190209\n\n\n\nid: ca_m_3411935_sw_11_060_20180724_20190209\n\n\nbbox: [-119.753736, 34.372185, -119.683827, 34.44028]\n\n\ngsd: 0.6\n\n\ndatetime: 2018-07-24T00:00:00Z\n\n\nnaip:year: 2018\n\n\nproj:bbox: [246978.0, 3806856.0, 253212.0, 3814248.0]\n\n\nproj:epsg: 26911\n\n\nnaip:state: ca\n\n\nproj:shape: [12320, 10390]\n\n\nproj:transform: [0.6, 0.0, 246978.0, 0.0, -0.6, 3814248.0, 0.0, 0.0, 1.0]\n\n\n\n\nSTAC Extensions\n\n\n\nhttps://stac-extensions.github.io/eo/v1.0.0/schema.json\n\n\nhttps://stac-extensions.github.io/projection/v1.0.0/schema.json\n\n\n\n\n\nAssets\n\n\n\n\n\nAsset: RGBIR COG tile\n\n\n\nhref: https://naipeuwest.blob.core.windows.net/naip/v002/ca/2018/ca_060cm_2018/34119/m_3411935_sw_11_060_20180724_20190209.tif?st=2023-11-26T21%3A18%3A54Z&se=2023-12-04T21%3A18%3A54Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-27T21%3A18%3A53Z&ske=2023-12-04T21%3A18%3A53Z&sks=b&skv=2021-06-08&sig=yOs1LiWCX0hM/gh73pDEEA2ae6DeSdqwRWLQBSvyu3Q%3D\n\n\ntype: image/tiff; application=geotiff; profile=cloud-optimized\n\n\ntitle: RGBIR COG tile\n\n\nroles: ['data']\n\n\nowner: ca_m_3411935_sw_11_060_20180724_20190209\n\n\neo:bands: [{'name': 'Red', 'common_name': 'red'}, {'name': 'Green', 'common_name': 'green'}, {'name': 'Blue', 'common_name': 'blue'}, {'name': 'NIR', 'common_name': 'nir', 'description': 'near-infrared'}]\n\n\n\n\n\n\n\n\n\n\nAsset: FGDC Metdata\n\n\n\nhref: https://naipeuwest.blob.core.windows.net/naip/v002/ca/2018/ca_fgdc_2018/34119/m_3411935_sw_11_060_20180724.txt?st=2023-11-26T21%3A18%3A54Z&se=2023-12-04T21%3A18%3A54Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-27T21%3A18%3A53Z&ske=2023-12-04T21%3A18%3A53Z&sks=b&skv=2021-06-08&sig=yOs1LiWCX0hM/gh73pDEEA2ae6DeSdqwRWLQBSvyu3Q%3D\n\n\ntype: text/plain\n\n\ntitle: FGDC Metdata\n\n\nroles: ['metadata']\n\n\nowner: ca_m_3411935_sw_11_060_20180724_20190209\n\n\n\n\n\n\n\n\n\n\nAsset: Thumbnail\n\n\n\nhref: https://naipeuwest.blob.core.windows.net/naip/v002/ca/2018/ca_060cm_2018/34119/m_3411935_sw_11_060_20180724_20190209.200.jpg?st=2023-11-26T21%3A18%3A54Z&se=2023-12-04T21%3A18%3A54Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-27T21%3A18%3A53Z&ske=2023-12-04T21%3A18%3A53Z&sks=b&skv=2021-06-08&sig=yOs1LiWCX0hM/gh73pDEEA2ae6DeSdqwRWLQBSvyu3Q%3D\n\n\ntype: image/jpeg\n\n\ntitle: Thumbnail\n\n\nroles: ['thumbnail']\n\n\nowner: ca_m_3411935_sw_11_060_20180724_20190209\n\n\n\n\n\n\n\n\n\n\nAsset: TileJSON with default rendering\n\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=ca_m_3411935_sw_11_060_20180724_20190209&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\n\n\ntype: application/json\n\n\ntitle: TileJSON with default rendering\n\n\nroles: ['tiles']\n\n\nowner: ca_m_3411935_sw_11_060_20180724_20190209\n\n\n\n\n\n\n\n\n\n\nAsset: Rendered preview\n\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=ca_m_3411935_sw_11_060_20180724_20190209&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png\n\n\ntype: image/png\n\n\ntitle: Rendered preview\n\n\nroles: ['overview']\n\n\nowner: ca_m_3411935_sw_11_060_20180724_20190209\n\n\nrel: preview\n\n\n\n\n\n\n\nLinks\n\n\n\n\n\nLink:\n\n\n\nrel: collection\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\n\n\ntype: application/json\n\n\n\n\n\n\n\n\n\n\nLink:\n\n\n\nrel: parent\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip\n\n\ntype: application/json\n\n\n\n\n\n\n\n\n\n\nLink: Microsoft Planetary Computer STAC API\n\n\n\nrel: root\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1\n\n\ntype: application/json\n\n\ntitle: Microsoft Planetary Computer STAC API\n\n\n\n\n\n\n\n\n\n\nLink:\n\n\n\nrel: self\n\n\nhref: https://planetarycomputer.microsoft.com/api/stac/v1/collections/naip/items/ca_m_3411935_sw_11_060_20180724_20190209\n\n\ntype: application/geo+json\n\n\n\n\n\n\n\n\n\n\nLink: Map of item\n\n\n\nrel: preview\n\n\nhref: https://planetarycomputer.microsoft.com/api/data/v1/item/map?collection=naip&item=ca_m_3411935_sw_11_060_20180724_20190209\n\n\ntype: text/html\n\n\ntitle: Map of item"
  },
  {
    "objectID": "blog/STAC-search.html#item",
    "href": "blog/STAC-search.html#item",
    "title": "Access",
    "section": "Item",
    "text": "Item\nLet‚Äôs get the first item in the search:\n\n# get first item in the catalog search\nitem = items[0]\ntype(item)\n\npystac.item.Item\n\n\nRemember the STAC item is the core object in the catalog.\nThe item does not contain the data itself, but rather metadata about and links to access the actual data (assets). Some of the metadata:\n\nitem.properties\n\n{'gsd': 0.6,\n 'datetime': '2020-05-21T00:00:00Z',\n 'naip:year': '2020',\n 'proj:bbox': [246930.0, 3806808.0, 253260.0, 3814296.0],\n 'proj:epsg': 26911,\n 'naip:state': 'ca',\n 'proj:shape': [12480, 10550],\n 'proj:transform': [0.6, 0.0, 246930.0, 0.0, -0.6, 3814296.0, 0.0, 0.0, 1.0]}\n\n\nJust as the item properties, the item assets are given in a dictionary, with each value being an pystac.asset Let‚Äôs check the assets in the item:\n\nitem.assets # links to the actual data\n\n{'image': &lt;Asset href=https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.tif?st=2023-11-26T21%3A18%3A54Z&se=2023-12-04T21%3A18%3A54Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-27T21%3A18%3A53Z&ske=2023-12-04T21%3A18%3A53Z&sks=b&skv=2021-06-08&sig=yOs1LiWCX0hM/gh73pDEEA2ae6DeSdqwRWLQBSvyu3Q%3D&gt;,\n 'thumbnail': &lt;Asset href=https://naipeuwest.blob.core.windows.net/naip/v002/ca/2020/ca_060cm_2020/34119/m_3411935_sw_11_060_20200521.200.jpg?st=2023-11-26T21%3A18%3A54Z&se=2023-12-04T21%3A18%3A54Z&sp=rl&sv=2021-06-08&sr=c&skoid=c85c15d6-d1ae-42d4-af60-e2ca0f81359b&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2023-11-27T21%3A18%3A53Z&ske=2023-12-04T21%3A18%3A53Z&sks=b&skv=2021-06-08&sig=yOs1LiWCX0hM/gh73pDEEA2ae6DeSdqwRWLQBSvyu3Q%3D&gt;,\n 'tilejson': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/tilejson.json?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png&gt;,\n 'rendered_preview': &lt;Asset href=https://planetarycomputer.microsoft.com/api/data/v1/item/preview.png?collection=naip&item=ca_m_3411935_sw_11_060_20200521&assets=image&asset_bidx=image%7C1%2C2%2C3&format=png&gt;}\n\n\n\nfor key in item.assets.keys():\n    print(key, '--', item.assets[key].title)\n\nimage -- RGBIR COG tile\nthumbnail -- Thumbnail\ntilejson -- TileJSON with default rendering\nrendered_preview -- Rendered preview\n\n\nNotice each asset has an href, which is a link to the asset object (i.e.¬†the data). For example, we can use the URL for the rendered preview asset to plot it:\n\n# plot rendered preview\nImage(url=item.assets['rendered_preview'].href, width=500)"
  },
  {
    "objectID": "blog/STAC-search.html#load-data",
    "href": "blog/STAC-search.html#load-data",
    "title": "Access",
    "section": "Load Data",
    "text": "Load Data\nThe raster data in our current item is in the image asset. Again, we access this data via its URL. This time, we open it using rioxr.open_rasterio() directly:\n\nsb = rioxr.open_rasterio(item.assets['image'].href)\nsb\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 4, y: 12480, x: 10550)&gt;\n[526656000 values with dtype=uint8]\nCoordinates:\n  * band         (band) int64 1 2 3 4\n  * x            (x) float64 2.469e+05 2.469e+05 ... 2.533e+05 2.533e+05\n  * y            (y) float64 3.814e+06 3.814e+06 ... 3.807e+06 3.807e+06\n    spatial_ref  int64 0\nAttributes:\n    AREA_OR_POINT:             Area\n    TIFFTAG_IMAGEDESCRIPTION:  OrthoVista\n    TIFFTAG_RESOLUTIONUNIT:    1 (unitless)\n    TIFFTAG_SOFTWARE:          Trimble Germany GmbH\n    TIFFTAG_XRESOLUTION:       1\n    TIFFTAG_YRESOLUTION:       1\n    _FillValue:                0\n    scale_factor:              1.0\n    add_offset:                0.0xarray.DataArrayband: 4y: 12480x: 10550...[526656000 values with dtype=uint8]Coordinates: (4)band(band)int641 2 3 4array([1, 2, 3, 4])x(x)float642.469e+05 2.469e+05 ... 2.533e+05array([246930.3, 246930.9, 246931.5, ..., 253258.5, 253259.1, 253259.7])y(y)float643.814e+06 3.814e+06 ... 3.807e+06array([3814295.7, 3814295.1, 3814294.5, ..., 3806809.5, 3806808.9, 3806808.3])spatial_ref()int640crs_wkt :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314140356inverse_flattening :298.257222101reference_ellipsoid_name :GRS 1980longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :NAD83horizontal_datum_name :North American Datum 1983projected_crs_name :NAD83 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"NAD83 / UTM zone 11N\",GEOGCS[\"NAD83\",DATUM[\"North_American_Datum_1983\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6269\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4269\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"26911\"]]GeoTransform :246930.0 0.6 0.0 3814296.0 0.0 -0.6array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1, 2, 3, 4], dtype='int64', name='band'))xPandasIndexPandasIndex(Index([          246930.3,           246930.9,           246931.5,\n       246932.09999999998, 246932.69999999998,           246933.3,\n                 246933.9,           246934.5, 246935.09999999998,\n       246935.69999999998,\n       ...\n                 253254.3,           253254.9,           253255.5,\n       253256.09999999998, 253256.69999999998,           253257.3,\n                 253257.9,           253258.5, 253259.09999999998,\n       253259.69999999998],\n      dtype='float64', name='x', length=10550))yPandasIndexPandasIndex(Index([         3814295.7,          3814295.1,          3814294.5,\n       3814293.9000000004, 3814293.3000000003,          3814292.7,\n                3814292.1,          3814291.5, 3814290.9000000004,\n       3814290.3000000003,\n       ...\n                3806813.7,          3806813.1,          3806812.5,\n       3806811.9000000004, 3806811.3000000003,          3806810.7,\n                3806810.1,          3806809.5, 3806808.9000000004,\n       3806808.3000000003],\n      dtype='float64', name='y', length=12480))Attributes: (9)AREA_OR_POINT :AreaTIFFTAG_IMAGEDESCRIPTION :OrthoVistaTIFFTAG_RESOLUTIONUNIT :1 (unitless)TIFFTAG_SOFTWARE :Trimble Germany GmbHTIFFTAG_XRESOLUTION :1TIFFTAG_YRESOLUTION :1_FillValue :0scale_factor :1.0add_offset :0.0\n\n\nNotice this raster has four bands. So we cannot use the .plot.imshow() method directly (as this function only works when we have three bands). Thus we need select the bands we want to plot (RGB) before plotting:\n\n# plot raster with correct ratio\nsize = 6 # height in in of plot height\naspect = sb.rio.width / sb.rio.height \n# select R,G,B bands and plot\nsb.sel(band=[1,2,3]).plot.imshow(size=size, aspect=aspect)\n\n&lt;matplotlib.image.AxesImage at 0x7fd129f1c250&gt;"
  },
  {
    "objectID": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#datasets",
    "href": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#datasets",
    "title": "2021 Thomas Fire Air Quality Index and Fire Scar Analysis",
    "section": "Datasets",
    "text": "Datasets\nEPA‚Äôs Air Quality Data Collected at Outdoor Monitor Stations\nThe first dataset contains information on daily AQI readings across the United States. AQI readings are an indicator that allow the public to understand how polluted their air is. Higher levels in AQI translate to more pollution present in the atmosphere.\nThis dataset has been download from the EPA‚Äôs Air Quality System (AQS).\nAdditional information and metadata for this datset is available in the Airdata Download Files Documentation\nCalifornia Fire Perimeter\nAs noted by The State of California and the Department of Forestry and Fire Protection this data provides a spatial distribution of the past large fires in California. But, this data is in no way a complete potrayal of the past fires.\nThis shapefile has been downloaded from California Govt State Geoportal.\nAdditional data can be found in the Fire Perimeters Description\nLandsat Data\nThis is a NetCDF file of a raster of Santa Barbara visualizing Santa Barbara. The data was accessed and pre-processed in the Microsoft Planetary Computer. The raster consists of three dimensions: x,y, band. It also contains the following data variables: red, green, blue, nir08(near infared), swir22(short wave).\nAdditional information regarding the Landsat bands can be found at the following USGS websites."
  },
  {
    "objectID": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#data-preparation",
    "href": "blog/2023-12-23-SB-Thomas-Fire/santa_barbara_thomas_fire.html#data-preparation",
    "title": "2021 Thomas Fire Air Quality Index and Fire Scar Analysis",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nAQI\nBefore I can plot a time series of the daily AQI I need to prepare the data. I need to combine the two years(2017 and 2018) of AQI, clean the columns, and update the object types.\n\n# \"Glue\" aqi_17 and aqi_18\naqi = pd.concat([aqi_17,aqi_18])\n\n# Update column by making lower case and replace space with underscore\naqi.columns = aqi.columns.str.lower().str.replace(' ','_')\n\n# update date column to be datetime object\naqi = aqi.copy()\naqi.date = pd.to_datetime(aqi.date)\n\n# Set date to indez\naqi = aqi.set_index(\"date\")\n\n\n\nLandsat Data Preparation\nThe landsat data contains an extra dimension, band, that is not necessary and can cause some issues when plotting. I will remove this dimension.\n\n# remove length 1 dimension (band)\nlandsat = landsat.squeeze()\n\n# remove coordinates associated to band\nlandsat = landsat.drop('band')\n\n\n\nWildfire Data Preparation\nLets explore our Wildfire shapefile, update the column names, and update the CRS to the landsat CRS.\n\n# Make column names lowercase\nwildfires.columns = wildfires.columns.str.lower()\n\n#Update wildfire CRS to match Landsar CRS\nwildfires = wildfires.to_crs(landsat.rio.crs)"
  },
  {
    "objectID": "blog/2023-12-13-houston-power-outage/texas_power.html",
    "href": "blog/2023-12-13-houston-power-outage/texas_power.html",
    "title": "Houston 2021 Power Outage: Socioeconomic Analysis",
    "section": "",
    "text": "In February 2021, Texas suffered a major power power crisis with more than 4.5 million homes and businesses were left without power for several days1. Historically power outages have disproportionately affected people of color and low income communities. They take longer to recover from the disaster because of fewer resources available to them2. More information regarding the engineering and political background are hyper linked.\nI am interested in investigating if socioeconomic status played a factor in community recovery from the power outage."
  },
  {
    "objectID": "blog/2023-12-13-houston-power-outage/texas_power.html#background-information",
    "href": "blog/2023-12-13-houston-power-outage/texas_power.html#background-information",
    "title": "Houston 2021 Power Outage: Socioeconomic Analysis",
    "section": "",
    "text": "In February 2021, Texas suffered a major power power crisis with more than 4.5 million homes and businesses were left without power for several days1. Historically power outages have disproportionately affected people of color and low income communities. They take longer to recover from the disaster because of fewer resources available to them2. More information regarding the engineering and political background are hyper linked.\nI am interested in investigating if socioeconomic status played a factor in community recovery from the power outage."
  },
  {
    "objectID": "blog/2023-12-13-houston-power-outage/texas_power.html#data",
    "href": "blog/2023-12-13-houston-power-outage/texas_power.html#data",
    "title": "Houston 2021 Power Outage: Socioeconomic Analysis",
    "section": "Data",
    "text": "Data\nMy analysis utilized the following data sets:\nVisible Infrared Imaging Radiometer Suite\nRemotely-sensed night light raster I am interested in tiles from 2021-02-07 and 2021-02-16.\nOpenStreetMap:\nThis contains - Subset of roads that intersect the Houston metropolitan area - Houses in the Houston Metropolitan area\nU.S. Census Bureau‚Äôs American Community Survey (ACS)\nContains socioeconomic data for each census block"
  },
  {
    "objectID": "blog/2023-12-13-houston-power-outage/texas_power.html#data-preparation",
    "href": "blog/2023-12-13-houston-power-outage/texas_power.html#data-preparation",
    "title": "Houston 2021 Power Outage: Socioeconomic Analysis",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nLoad Libraries\nLoad the necessary libraries. I will mainly be working with stars, sf and ggplot2.\n\n# Libraries\nlibrary(tmap)\nlibrary(sf)\nlibrary(terra)\nlibrary(raster)\nlibrary(stars)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(dplyr)\nlibrary(ggspatial)\nlibrary(patchwork)\n\n\n\nNight Lights\nFirst import all of the required data using the stars package. Then it can be conjoined into a single composite.\n\n## Import tiles for 2021-02-07 and 2021-02-16\n# tile h08v05, collected on 2021-02-07 \nfeb7_h &lt;- read_stars(\"data/VNP46A1/VNP46A1.A2021038.h08v05.001.2021039064328.tif\")\n\n# tile h08v06, collected on 2021-02-07 \nfeb7_v &lt;-read_stars(\"data/VNP46A1/VNP46A1.A2021038.h08v06.001.2021039064329.tif\")\n\n# tile h08v05, collected on 2021-02-16 \nfeb16_h &lt;- read_stars(\"data/VNP46A1/VNP46A1.A2021047.h08v05.001.2021048091106.tif\")\n\n# tile h08v06, collected on 2021-02-16 \nfeb16_v &lt;- read_stars(\"data/VNP46A1/VNP46A1.A2021047.h08v06.001.2021048091105.tif\")\n\n## Convert to stars object\nstars_207 &lt;- st_mosaic(feb7_h,feb7_v)\nstars_216 &lt;- st_mosaic(feb16_h,feb16_v)\n\nI am interested in seeing the difference in night lights intensity from before and after the storm.\n\n# change in night lights intensity (2/07 - 2/16)\nchange_lights &lt;- stars_207 - stars_216\n\nI assume that any location that experienced a drop of more than 200 NW cm-2sr-1 experienced a blackout. Locations that experienced a drop of less than 200 NW cm-2sr-1 did not experience a blackout and are assigned NA values.\n\n# reclassify differences: blackout (&gt; 200 nWcm^-2^sr^-1) and NA (&lt;200) \ndem_rcl &lt;- cut(change_lights,\n              breaks=c(-Inf,200,Inf),\n              labels = c(\"blackout\",\"no blackout\"))\n\n# assign `NA` to all locations that experienced a drop of *less* than 200 nW cm^-2^sr^-1\nchange_lights[change_lights &lt;= 200] = NA\n\nMy area of interest is the Houston metropolitan area and is located within the following coordinates: (-96.5, 29), (-96.5, 30.5), (-94.5, 30.5), (-94.5, 29). I can crop my blackout mask to this area.\n\n# Define the Houston metropolitan area \ncoord_box &lt;- matrix(c(-96.5,29,-96.5,30.5,-94.5,30.5,-94.5,29,-96.5,29), \n                    ncol = 2, \n                    byrow = TRUE)\n\n# Create a polygon with coordinates\npolygon &lt;- st_polygon(list(coord_box))\n\n# Convert the polygon into a simple feature collection\n# Assign the CRS to blackout lights tiles\npolygon_sf &lt;- st_sfc(polygon, crs = st_crs(blackout_mask))\n\n# Crop (spatially subset) the blackout mask to our region of interest\nhouston_mask &lt;- st_crop(blackout_mask,polygon_sf)\n\n# Reproject cropped blackout dataset to EPSG:3083\nhouston_mask &lt;- st_transform(houston_mask, crs = \"EPSG:3083\")\n\n\n\nHighways\nHighways typically account for most of the night light seen from space. To remove the potential error of identifying the wrong areas, I will exclude highways from the blackout mask.\nThe roads geopackage contains more than highway data so using SQL I selected just motorway data.\nOnce I have selected the necessary data I can buffer and identify areas that experience blackouts further than 200m from a highway.\n\n# Re-project data to EPSG:3083\nhighway &lt;- st_transform(highway,crs = \"EPSG:3083\")\n\n# Identify areas within 200m of all highways\nhighways_200 &lt;- highway %&gt;% st_buffer(dist = 200) %&gt;%  st_union()\n\n## Identify the areas in houston that experienced blackouts further than 200m from a highway\nhouston_blackout &lt;- st_difference(houston_mask,highways_200)\n\n\n\nHomes Impacted by Blackout\nUsing SQL I selected only residential buildings from OpenStreetMap. Residential buildings include: residential, apartments, house, static caravan, and detached.\n\n#SQL query to select only residential buildings\nquery &lt;- \"SELECT * FROM gis_osm_buildings_a_free_1 WHERE (type IS NULL AND name IS NULL) OR type in ('residential', 'apartments', 'house', 'static_caravan', 'detached')\"\n\n# Import residential buildings\nbuildings_data &lt;- st_read(\"data/gis_osm_buildings_a_free_1.gpkg\", query = query)\n\n# Transform buildings data CRS to EPSG:3083\nbuildings_data &lt;- st_transform(buildings_data, crs = \"EPSG:3083\")\n\nI can now filter to count the number of homes impacted within the blackout areas.\n\n# Filter to homes within blackout areas\nhomes_blackout &lt;- buildings_data %&gt;% st_filter(houston_blackout,\n                          .predicate = st_intersects)\n\npaste(\"Number of impacted homes:\",nrow(homes_blackout))\n\n[1] \"Number of impacted homes: 157410\"\n\n\n\n\nSocioeconomic Factors\nThe ACS data is composed of geodatabase layers. The geometries are stored in the ACS_2019_5YR_TRACT_48_TEXAS layer and income is stored in the median income field B19013e1. Using SQL both of these can be filtered to.\n\n#View ACS layers\nst_layers(\"data/ACS_2019_5YR_TRACT_48_TEXAS.gdb\")\n# Read in geometries and change CRS to EPSG 3083\ntexas_geometries &lt;- st_read(\"data/ACS_2019_5YR_TRACT_48_TEXAS.gdb\", \n                          layer = \"ACS_2019_5YR_TRACT_48_TEXAS\") %&gt;% \n  st_transform(crs = \"EPSG:3083\")\n\n# Read in ACS data in X19_INCOME layer and select B19013e1 column\ntexas_median_income &lt;-\n  st_read(\"data/ACS_2019_5YR_TRACT_48_TEXAS.gdb\",\n    layer = \"X19_INCOME\") %&gt;% \n  select('GEOID', 'B19013e1') %&gt;% \n  rename(\"median_income\" = 'B19013e1',\n         \"GEOID_Data\" = \"GEOID\")\n\nI am only interested in income census tracts that experienced blackouts in the Houston boundaries. Through spatial joining and cropping I can filter to these specific census blocks.\n\n# Join the income data to the census tract geometries \nincome_geom &lt;- left_join(texas_geometries,texas_median_income, by = \"GEOID_Data\") %&gt;% st_transform(crs = \"EPSG:3083\")\n\n# Transform Houston polygon CRS to match income_geom \npolygon_sf &lt;- st_transform(polygon_sf, crs = st_crs(income_geom))\n\n# Crop census income data to just Houston area\nhouston_geom &lt;- st_crop(income_geom,polygon_sf)\n\n## spatially join census tract data with buildings determined to be impacted by blackouts\nhouston_blackout &lt;- st_join(houston_geom,homes_blackout, left = FALSE)\n\n## Census tracts had blackouts - by unique census track\npaste(\"Number of unique census tracks had blackouts:\",length(unique(houston_blackout$GEOID)))\n\n[1] \"Number of unique census tracks had blackouts: 754\""
  },
  {
    "objectID": "blog/2023-12-13-houston-power-outage/texas_power.html#visualization",
    "href": "blog/2023-12-13-houston-power-outage/texas_power.html#visualization",
    "title": "Houston 2021 Power Outage: Socioeconomic Analysis",
    "section": "Visualization",
    "text": "Visualization\nI can visualize a map of median income by census tract, designating which tracts had blackouts by outlining them.\n\n#Create a map of median income by census tract\n# Census tracts that had blackouts are designated as red\nvisual &lt;- ggplot() +\n  geom_sf(data = houston_geom, aes(fill = median_income)) +\n  geom_sf(\n    data = houston_blackout,\n    aes(color = 'red'),\n    fill = NA,\n    show.legend = 'abs'\n  ) +\n  scale_fill_viridis_c() +  \n  scale_color_identity(guide = \"legend\",name = \"\",labels = \"Blackout area\", breaks = 'red') +\n  annotation_scale(location = 'bl', width = 0.1) +\n  annotation_north_arrow(location = 'br',height = unit(.8, \"cm\"),\n  width = unit(.8, \"cm\"), style = north_arrow_fancy_orienteering()) +\n  labs(title = \"Houston Median Income Across Census Tracks with Blackouts\") +\n  theme_minimal() \n\nvisual\n\n\n\n\nTo get a better understanding of the distribution of income in impacted and un-impacted zones, I plotted them as histograms side-by-side.\n\n# Simplify and clean Houston census tracks in blackout zone\nhouston_blackout_dist &lt;- houston_blackout %&gt;% \n  select(GEOID,median_income) %&gt;% unique()\n\n# Income distribution on impacted census tracts\np1 &lt;- ggplot(houston_blackout_dist, aes(x = median_income)) +\n  geom_histogram(bins = 20, fill = 'orange', color = 'black') +\n  labs(x = 'Median Income', y ='Count', title = 'Income Distribution of Impacted Census Tracts') + ylim(0,150) + theme(text=element_text(size=7))\n\n#Clean up Houston geom \nhouston_geom_dist &lt;- houston_geom %&gt;% select(GEOID,median_income) %&gt;% unique\n\n# Identify the census track that were not affected by the blackout\nhouston_non &lt;- setdiff(houston_geom_dist,houston_blackout_dist)\n\n# Plot income distribution of census tracts not affected by the blackout\np2 &lt;- ggplot(data = houston_non, aes(x = median_income)) +\n  geom_histogram(bins = 20,\n                 fill = '#4398F9',\n                 color = 'black') +\n  ylim(0, 150) + \n  labs(x = \"Median Income\",\n       y = \"Count\", \n       title = \"Income Distribution of Unimpacted Census Tracts\") + \n  theme(text = element_text(size = 7))\n\n# Turn plots interactive\np1 &lt;- ggplotly(p1)\n\np2 &lt;- ggplotly(p2)\n\n# Set them side by side\nsubplot(p1, p2, nrows = 1)"
  },
  {
    "objectID": "blog/2023-12-13-houston-power-outage/texas_power.html#conclusion",
    "href": "blog/2023-12-13-houston-power-outage/texas_power.html#conclusion",
    "title": "Houston 2021 Power Outage: Socioeconomic Analysis",
    "section": "Conclusion",
    "text": "Conclusion\nThe income distribution of the impacted census tract has a similar distribution of the un-impacted census tract. They both display a right skew with the majority of the distribution being in the lower income range. During this storm income level of the census tract did not display a large effect based solely on the graphs generated. There are some limitations to this study such as the limitation of spatial data in the days during the storm because of the cloud coverage. The raster data I analyzed is during the second storm and does not account for the third storm. Also, there is the issue of the year the ACS data represents. The income demographic are from 2019, these could have changed since then and potentially do not accurately represent the income distribution of Houston during the storm."
  },
  {
    "objectID": "blog/2023-12-13-houston-power-outage/texas_power.html#footnotes",
    "href": "blog/2023-12-13-houston-power-outage/texas_power.html#footnotes",
    "title": "Houston 2021 Power Outage: Socioeconomic Analysis",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDouglas, E. (2021, February 20). Gov.¬†Greg Abbott wants power companies to ‚ÄúWinterize.‚Äù Texas‚Äô track record won‚Äôt make that easy. The Texas Tribune. https://www.texastribune.org/2021/02/20/texas-power-grid-winterize/‚Ü©Ô∏é\nDobbins, J., & Tabuchi, H. (2021, February 16). Texas blackouts hit minority neighborhoods especially hard. Texas Blackouts Hit Minority Neighborhoods Especially Hard. https://www.nytimes.com/2021/02/16/climate/texas-blackout-storm-minorities.html‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/2023-12-15-az-west-nile-endemic-analysis/west_nile_virus.html",
    "href": "blog/2023-12-15-az-west-nile-endemic-analysis/west_nile_virus.html",
    "title": "2021 Maricopa County - West Nile Endemic",
    "section": "",
    "text": "The West Nile Virus is the most common cause of mosquito-borne diseases in the United States. Since its first reported case in 1999, there have been a total of 55,443 cases.1While some may experience mild symptoms such as rashes, body aches, and vomiting. For others the West Nile Virus(WNV) can cause severe central nervous system damage and can result in death.2\nThis project will focus on WNV cases in Maricopa County, AZ. Between 2009 and 2018, it‚Äôs among six counties in the United States that experienced elevated occurrences of West Nile virus cases.3 WNV is an endemic in Maricopa County, since it was first detected in 2003 there have been 4 outbreaks.4 Their largest outbreak was during 2021, a total of 1,487 human WNV cases were identified; 956 (64.3%) patients had neuroinvasive disease, and 101 (6.8%) died.5 Officials believe that the severe Monsoon experienced, June 15 through September 30 was a cause behind the increase in cases.6\n\nWNV is dependent on temperature, precipitation, and bird migratory patterns. All of these are being negatively impacted by climate change, which is expanding the geographical range of mosquitoes. Climate change is increasing the risk of human exposure to WNV, warmer temperatures are accelerating mosquito development, rainfall creates breeding sites, and the timing of bird migratory patterns are changing. Precipitation has been associated with an increase in 29-66% of reported cases with a single-day rainfall of at least 50mm within 3 weeks of diagnosis7.\nMaricopa County might not be the only county reporting endemics in the next few decades.\nQuestion\nFor Maricopa County‚Äôs 2021 outbreak what is the lag for precipitation with respect to reported cases?"
  },
  {
    "objectID": "blog/2023-12-15-az-west-nile-endemic-analysis/west_nile_virus.html#background",
    "href": "blog/2023-12-15-az-west-nile-endemic-analysis/west_nile_virus.html#background",
    "title": "2021 Maricopa County - West Nile Endemic",
    "section": "",
    "text": "The West Nile Virus is the most common cause of mosquito-borne diseases in the United States. Since its first reported case in 1999, there have been a total of 55,443 cases.1While some may experience mild symptoms such as rashes, body aches, and vomiting. For others the West Nile Virus(WNV) can cause severe central nervous system damage and can result in death.2\nThis project will focus on WNV cases in Maricopa County, AZ. Between 2009 and 2018, it‚Äôs among six counties in the United States that experienced elevated occurrences of West Nile virus cases.3 WNV is an endemic in Maricopa County, since it was first detected in 2003 there have been 4 outbreaks.4 Their largest outbreak was during 2021, a total of 1,487 human WNV cases were identified; 956 (64.3%) patients had neuroinvasive disease, and 101 (6.8%) died.5 Officials believe that the severe Monsoon experienced, June 15 through September 30 was a cause behind the increase in cases.6\n\nWNV is dependent on temperature, precipitation, and bird migratory patterns. All of these are being negatively impacted by climate change, which is expanding the geographical range of mosquitoes. Climate change is increasing the risk of human exposure to WNV, warmer temperatures are accelerating mosquito development, rainfall creates breeding sites, and the timing of bird migratory patterns are changing. Precipitation has been associated with an increase in 29-66% of reported cases with a single-day rainfall of at least 50mm within 3 weeks of diagnosis7.\nMaricopa County might not be the only county reporting endemics in the next few decades.\nQuestion\nFor Maricopa County‚Äôs 2021 outbreak what is the lag for precipitation with respect to reported cases?"
  },
  {
    "objectID": "blog/2023-12-15-az-west-nile-endemic-analysis/west_nile_virus.html#data-methods",
    "href": "blog/2023-12-15-az-west-nile-endemic-analysis/west_nile_virus.html#data-methods",
    "title": "2021 Maricopa County - West Nile Endemic",
    "section": "Data & Methods",
    "text": "Data & Methods\nWNV data was obtained from Arizona Department of Health Services Epidemiology & Disease Control. Two separate data sets were used:\n\nMonthly reported cases (2006 - 2021)\nWeekly reported cases (2021)\n\nMonthly precipitation data was obtained from USAFacts that has composed an accessible data format of NOAA‚Äôs National Centers for Environmental Information(NCEI).\nWhile weekly precipitation was obtained directly from NOAA NCEI Climate Data. Precipitation levels are gathered from 12 precipitation stations in Maricopa County and the extended area.\nMy analysis included conducting a Cross-Correlation Function (CCF) between weekly average precipitation time series and weekly reported cases time series. Then I ran a linear regression of the lag precipitation with the reported cases.\n\nData Exploration\nMy first approach was to plot my data. I conducted a time series from 2006 - 2021. As well as 2006-2020, excluding 2021 to view prior peak number of cases.\n\n# 2006-2021 reported cases plot\nw_2021 &lt;- ggplot(west_nile_2021, aes(x = date1, y = cases)) +\n  geom_line(color = \"blue\") +\n  scale_x_date(breaks = scales::pretty_breaks(n=10),date_labels = \"%b-%Y\") +\n    labs(x = \"Date\", title = \"2006-2021 reported cases\") + theme_classic()\n\n# 2006-2020 reported cases plot\nw_2020 &lt;- ggplot(west_nile_2020, aes(x = date1, y = cases)) +\n  geom_line(color = \"blue\") +\n  scale_x_date(breaks = scales::pretty_breaks(n = 10),\n               date_labels = \"%b-%Y\") +\n  labs(x = \"Date\",\n       title = \"2006-2020 reported cases\",\n       caption = \"Figure 1. Time series of reported cases from 2006 to 2021 and excluding 2021\") +\n  theme_classic()  +\n  theme(plot.caption = element_text(hjust = 0))\n\n# Combined plots\nw_2021 / w_2020\n\n\n\n\n\n# Decomposition of reported WNV cases \nas_tsibble(west_nile_2020) %&gt;% \n  model(classical_decomposition(cases, type = \"additive\")) %&gt;%\n  components() %&gt;%\n  autoplot() + labs(caption = \"Figure 2. Decomposition of reported cases 2006-2020\",\n                    title = \"Classical Decomposition of Reported WNV Cases\",\n                    x = \"Date\") +\n  theme(plot.caption = element_text(hjust = 0))\n\n\n\n\nThere does appear to be seasonality within WNV reported cases. But not much of a trend. I further analyzed the 2021 outbreak looking at weekly reported cases and weekly average precipitation.\n\n# Weekly reported cases\nweekly_cases_p &lt;- ggplot(cases_2021, aes(x = week, y = cases)) +\n  geom_line(color = \"red\") + labs(x = \"Week\", y = \"Reported Cases Count\") +\n  theme_classic()\n\n# Weekly average precipitation\nweekly_rainfall_p &lt;- ggplot(cases_2021, aes(x = week, y = average_prcp)) +\n  geom_line(color = \"deepskyblue3\") + \n  labs(x = \"Week\", \n       y = \"Average precipitation (in)\",\n       caption = \"Figure 3. Weekly cases and precipitation, 2021\") +\n  theme_classic() +\n  theme(plot.caption = element_text(hjust = 0))\n\n# Generate plot\nweekly_cases_p / weekly_rainfall_p\n\n\n\n\nObserving the plot created, average precipitation peaks at week 30. Reported cases peak lags a couple weeks afterwards."
  },
  {
    "objectID": "blog/2023-12-15-az-west-nile-endemic-analysis/west_nile_virus.html#statistical-analysis",
    "href": "blog/2023-12-15-az-west-nile-endemic-analysis/west_nile_virus.html#statistical-analysis",
    "title": "2021 Maricopa County - West Nile Endemic",
    "section": "Statistical Analysis",
    "text": "Statistical Analysis\nThe approach I took to determine the lag time for average precipitation with respect to reported cases was the method sample Cross-Correlation-Function (CCF).\n\n# Cross Correlation Functions CCF \nccf_values &lt;- ccf(cases_2021$cases, cases_2021$average_prcp)\n\n\n# Edit title and x-axis\nplot(ccf_values, \n     main = \"CCF lag for Cases and Average Precipitation\",\n     xlab = \"Weekly lags\")\n\n\n\n\nI determined the lag to be in 7 weeks. A 7 week lag of average precipitation is a predicate of weekly reported cases. In other words, an increase in rainfall tends to be followed by an increase in reported cases, but with a delay of 7 weeks. New precipitation and cases time series were created with the lag.\n\n# Create a lagged precipitation\n# Run a lag for 7 weeks\nlag7&lt;- lag(cases_2021$average_prcp, 7)\n#remove rows with NA values due to lag\nlag7 &lt;- na.omit(lag7)\n\n# remove first seven values of cases\ncases &lt;- cases_2021$cases[8:52]\n\nLinear Model\nTo verify the statistical significance of the determined lag, a linear model was created (Œ± &lt; 0.05).\n\n# Linear model\nmod &lt;- lm(cases ~ lag7)\n\ntab_model(mod, \n          pred.labels = c(\"Intercept\", \"Average precipitation w. 7 week lag\"),\n          dv.labels = \"Linear Model of Reported Cases\",\n          string.ci = \"Conf. Int (95%)\",\n          string.p = \"p-value\",\n          title = \"Table 1. Linear Model Results\",\n          digits = 4)\n\n\nTable 1. Linear Model Results\n\n\n¬†\nLinear Model of Reported Cases\n\n\nPredictors\nEstimates\nConf. Int (95%)\np-value\n\n\nIntercept\n12.7167\n-5.0063¬†‚Äì¬†30.4396\n0.155\n\n\nAverage precipitation w. 7 week lag\n684.8930\n473.8901¬†‚Äì¬†895.8959\n&lt;0.001\n\n\nObservations\n45\n\n\nR2 / R2 adjusted\n0.499 / 0.487\n\n\n\n\n\n\n\nThe results illustrate that average precipitation with a lag of 7 weeks is a significant predictor for reported weekly cases (p&lt;0.001). This linear model is statistically significant. On average we expect to see reported cases to increase by 684 for each one inch increase in average precipitation for 2021. Overall model predictability is moderate, 48% change of reported cases can be explained by average precipitation."
  },
  {
    "objectID": "blog/2023-12-15-az-west-nile-endemic-analysis/west_nile_virus.html#conclusion",
    "href": "blog/2023-12-15-az-west-nile-endemic-analysis/west_nile_virus.html#conclusion",
    "title": "2021 Maricopa County - West Nile Endemic",
    "section": "Conclusion",
    "text": "Conclusion\nAfter conducting the analysis, this model reveals the statistically significant relationship between precipitation and reported WNV cases. The findings suggests 7 weeks subsequent to changes in precipitation notable changes are seen in WNV reported cases.\nAlthough a high correlation is suggested, it is important to note the data sets small sample size of 52 samples. This can lead to potential bias. There is also the assumption that all reported cases of WNV were of residents exposed in Maricopa County. Positive cases could have been contracted outside of the county, but they are still included in the total count. In addition when averaging the 12 precipitation stations potential bias is introduced by assuming the reported cases are equally distributed across the county. If infections were predominantly concentrated in specific locations, the averaging of precipitation from multiple sites might dilute the impact of higher precipitation levels experienced in those areas. The disparities in infection distribution across the county could potentially mask the true association between extreme precipitation events in specific areas and the reported cases.\nFuture investigations should consider the location of reported cases in Maricopa county. As well as potentially expanding this analysis to include 2006 to 2021 data. It would be interesting to see if a 7 week lag of precipitation remains the same even for years that did not experience torrential rain. Or for years that saw a smaller outbreak.\nFurther data wrangling and analysis can be found at my Github repository."
  },
  {
    "objectID": "blog/2023-12-15-az-west-nile-endemic-analysis/west_nile_virus.html#footnotes",
    "href": "blog/2023-12-15-az-west-nile-endemic-analysis/west_nile_virus.html#footnotes",
    "title": "2021 Maricopa County - West Nile Endemic",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nClimate change indicators: West Nile virus US EPA. (n.d.). https://www.epa.gov/climate-indicators/climate-change-indicators-west-nile-virus‚Ü©Ô∏é\nBailey, M. (2022, March 29). Altered by climate change, the U.S. could become ideal for West Nile to thrive. PBS. https://www.pbs.org/newshour/health/altered-by-climate-change-the-u-s-could-become-ideal-for-west-nile-to-thrive#:~:text=For%20the%20three%20species%20of,the%20course%20of%20one%20day.‚Ü©Ô∏é\nMosquito Days Climate Central. (2020, July 29). https://www.climatecentral.org/climate-matters/more-mosquito-days‚Ü©Ô∏é\nMosquito Days Climate Central. (2020, July 29). https://www.climatecentral.org/climate-matters/more-mosquito-days‚Ü©Ô∏é\nCenters for Disease Control and Prevention. (n.d.). Migratory birds and spread of West Nile virus in the Western Hemisphere - volume 6, number 4-August 2000 - emerging infectious diseases journal - CDC. Centers for Disease Control and Prevention. https://wwwnc.cdc.gov/eid/article/6/4/00-0401_article#:~:text=Migratory%20birds%20have%20long%20been%20suspected%20as%20the%20principal%20introductory,of%20migratory%20birds%20(and%20mosquitoes‚Ü©Ô∏é\nCenters for Disease Control and Prevention. (n.d.). Migratory birds and spread of West Nile virus in the Western Hemisphere - volume 6, number 4-August 2000 - emerging infectious diseases journal - CDC. Centers for Disease Control and Prevention. https://wwwnc.cdc.gov/eid/article/6/4/00-0401_article#:~:text=Migratory%20birds%20have%20long%20been%20suspected%20as%20the%20principal%20introductory,of%20migratory%20birds%20(and%20mosquitoes‚Ü©Ô∏é\nWeinhold B. (2009). Rainy day reaction: human west nile viruses cases respond to weather patterns. Environmental health perspectives, 117(7), A311. https://doi.org/10.1289/ehp.117-a311b‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/2024-03-03-nyc-dead-trees/nyc-dead-trees.html",
    "href": "blog/2024-03-03-nyc-dead-trees/nyc-dead-trees.html",
    "title": "Visualizing NYC Dead Street Trees",
    "section": "",
    "text": "In this blog I will show the steps I took to create an infographic analyzing New York City‚Äôs (NYC) street trees. My over arching question is Are dead street trees an alarming concern for NYC?\nTo answer this question I will be answering the following subset of questions:\n\nWhat are the street trees health status?\nWhat neighborhood requires the most street tree rehabilitation?\nAre younger trees experiencing higher morality?"
  },
  {
    "objectID": "blog/2024-03-03-nyc-dead-trees/nyc-dead-trees.html#nyc-health-status-treemap",
    "href": "blog/2024-03-03-nyc-dead-trees/nyc-dead-trees.html#nyc-health-status-treemap",
    "title": "Visualizing NYC Dead Street Trees",
    "section": "NYC Health Status Treemap",
    "text": "NYC Health Status Treemap\nSince this dataset is about trees I had to use the treemap function for the first question. I was interested in getting an overall idea of the health status of the street trees across the 5 boroughs. The health status of the trees reported were subjective and based on the volunteers. They were categorized as good, fair, poor, and dead.\nI first grouped them by borough and summarized the number of trees in each health category. The next step required me to rearrange the format of my dataframe to prep it for the treemap package.\n\n\nCode\n# First Visualization ----\n# Treemap\n\n# Prepare data for treemap format\nbstatus <- nyc_trees %>% \n  select(boroname, health) %>% \n  group_by(health,boroname) %>% \n  summarise(count = n()) %>% \n  st_drop_geometry() %>% \n  mutate(health = replace_na(health, \"Dead\")) %>% \n  mutate(colors = ifelse(health %in% names(tree_map), tree_map[health],NA))\n\n# Treemap of NYC street tree health status\ntreemap(bstatus,\n        index = c(\"boroname\", \"health\"), \n        vSize = \"count\",\n        type = \"color\",\n        vColor = \"colors\", \n        fontsize.labels = c(12,9.5),\n        labels = FALSE,\n        bg.labels = 0,\n        border.col = \"white\",\n        border.lwds = 1.5,\n        fontcolor.labels = \"white\",\n        align.labels = list(c(\"center\",\"center\"),c(\"left\",\"top\")),\n        force.print.labels = TRUE,\n        title = \"NYC Street Tree Health Status\",\n        fontfamily.title = \"alegreya\",\n        fontface.labels = \"bold\"\n        ) \n\n\n\n\n\nAdditional edits to the treemap were done in Canva to add black borders over each borough."
  },
  {
    "objectID": "blog/2024-03-03-nyc-dead-trees/nyc-dead-trees.html#neighborhood-with-the-most-dead-trees-map",
    "href": "blog/2024-03-03-nyc-dead-trees/nyc-dead-trees.html#neighborhood-with-the-most-dead-trees-map",
    "title": "Visualizing NYC Dead Street Trees",
    "section": "Neighborhood with the most dead trees map",
    "text": "Neighborhood with the most dead trees map\nThe first part of this visualization is determine what borough has the highest amount of dead trees.\nData Preparation\n\n\nCode\n# Borough dead and stump tree count\nboro <- nyc_trees %>% \n  filter(status == \"Dead\" | status == \"Stump\") %>% \n  group_by(boroname) %>% \n  summarize(dead = n()) %>% \n  st_drop_geometry()\n\n\n# Borough alive trees count\nboro1 <- nyc_trees %>% \n  filter(status == \"Alive\") %>% \n  group_by(boroname) %>% \n  summarize(alive = n()) %>% \n  st_drop_geometry()\n\n# Merge\nboro_merge <- merge(boro, boro1)\n\n# Percent of dead trees\n# Bronx determined as having the highest percentage\nboro_merge <- boro_merge %>% \n  mutate(ratio = dead/alive)\n \ngt(boro_merge %>% \n     mutate(\"percent\" = round(ratio *100 ,3)) %>% \n     select(-ratio) %>% \n     arrange(desc(percent))) %>% \n  tab_header(title = \"Percent of dead street trees across the 5 Boroughs, NYC\")\n\n\n\n\n\n\n  \n    \n      Percent of dead street trees across the 5 Boroughs, NYC\n    \n    \n    \n      boroname\n      dead\n      alive\n      percent\n    \n  \n  \n    Bronx\n4618\n80585\n5.731\n    Queens\n12577\n237974\n5.285\n    Manhattan\n2996\n62427\n4.799\n    Brooklyn\n7549\n169744\n4.447\n    Staten Island\n3875\n101443\n3.820\n  \n  \n  \n\n\n\n\nThe Bronx is identified as the the borough with the highest percentage of dead tree. Then to further analyze I determined what neighborhood in the Bronx has the highest percentage of dead trees.\n\n\nCode\n### Neighborhood in the Bronx with highest amount of dead tree\nbronx_neigh_dead <- nyc_trees %>% \n  filter(boroname == \"Bronx\") %>% \n  filter(status == \"Dead\" |\n           status == \"Stump\") %>% \n  filter(boroname == \"Bronx\") %>% \n  group_by(nta_name) %>% \n  summarise(dead = n()) %>% \n  st_drop_geometry()\n  \n\n# Count number of alive trees by neighborhood in the Bronx\nbronx_neigh_alive <- nyc_trees %>% \n  filter(boroname == \"Bronx\") %>% \n  filter(status == \"Alive\") %>% \n  group_by(nta_name) %>% \n  summarise(alive = n()) %>% \n  st_drop_geometry()\n\n# Determine the percent of dead trees by neighborhoods\n# Bronxdale identified as the highest percentage\nbronx <- merge(bronx_neigh_dead, bronx_neigh_alive) %>% \n  mutate(ratio = (round(dead/alive, 3))) %>% \n  rename(ntaname = nta_name)\n\ngt(head(bronx %>% \n    mutate(\"percent\" = round(ratio*100,3)) %>%\n    select(-ratio) %>% \n      arrange(desc(percent)),5 )) %>% \n  tab_header(title = \"Top 5 Bronx Neighborhoods with the highest percent of dead street trees\")\n\n\n\n\n\n\n  \n    \n      Top 5 Bronx Neighborhoods with the highest percent of dead street trees\n    \n    \n    \n      ntaname\n      dead\n      alive\n      percent\n    \n  \n  \n    Bronxdale\n145\n1405\n10.3\n    Highbridge\n182\n1797\n10.1\n    East Concourse-Concourse Village\n213\n2285\n9.3\n    West Concourse\n174\n1968\n8.8\n    Eastchester-Edenwald-Baychester\n202\n2427\n8.3\n  \n  \n  \n\n\n\n\nBronxdale was identified as the neighborhood in the Bronx with the highest percent of dead trees.\nNext I prepped the boundary for Bronxdale neighborhood.\n\n\nCode\n# BRONX boundary\nbronx_bounds <- nyc_boundary %>% \n  filter(boro_name == \"Bronx\")\n\n# Check CRS\n#st_crs(bronx_bounds) == st_crs(nyc_trees)\n\n# Bronxdale\nbronxdale <- bronx_bounds %>% \n  filter(ntaname == \"Bronxdale\")\n\n# Dead Trees in the Bronx\nbronx_dead <- nyc_trees %>% \n  filter(boroname == \"Bronx\") %>% \n  filter(status %in% c(\"Dead\", \"Stump\"))\n\n# Remove neighborhood boundaries and have full Bronx shape\nbronx <- st_union(bronx_bounds)\n\n# Highlight were Bronxdale is located\nleaflet() %>% \n  addTiles() %>% \n  addProviderTiles(providers$CartoDB) %>% \n  addPolygons(data = bronx, color = \"black\",\n              fillColor = NA,\n              opacity = 0.8, weight = 1) %>% \n  addPolygons(data = bronxdale, color = \"red\")\n\n\n\n\n\n\nI was able to calculate the frequency of dead street trees for each street by creating a buffer around the streets. Any tree that fell within that buffer was countes as a part of that street.\n\n\nCode\n## Load in Highways and roads in Bronxdale ----\nbush_roads_raw <- \n  st_bbox(bronxdale) %>%\n  opq() %>%\n  add_osm_feature(\"highway\") %>%\n  osmdata_sf()\n\n\nbush_outline <- \n  bronxdale %>%\n  st_simplify() %>%\n  st_union() %>%\n  st_buffer(dist = 0.001)\n\n\nbush_roads <- \n  bush_roads_raw$osm_lines %>%\n  st_transform(st_crs(bronxdale)) %>%\n  st_crop(st_bbox(bronxdale)) %>% \n  st_transform(3488) ## transform to meters\n\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\nCode\n# CRS transforms ----\nbush_roads <- st_transform(bush_roads, crs = st_crs(bronxdale))\n\nbush_roads_buffer <- \n  bush_roads %>% \n  st_buffer(dist = 20, endCapStyle = \"FLAT\")\n\n\nbush_roads_buffer <- st_transform(bush_roads_buffer, crs = st_crs(bronxdale))\nbronx_dead <- st_transform(bronx_dead, crs = st_crs(bronxdale))\n\n\n\nsf_roads_trees <- bush_roads %>% \n  mutate(\n    length = as.numeric(st_length(.)),\n    tree_count = lengths(st_intersects(bush_roads_buffer, bronx_dead))\n  ) \n\n# Clip frequency of trees to Bronxdale \nbbbb <- st_intersection(bronxdale, sf_roads_trees)\n\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\nCode\n# Zero streets\nzero_streets <- bbbb %>% \n  filter(tree_count == 0)\n\n# Count of trees on streets\ntree_streets <- bbbb %>% \n  filter(tree_count != 0)\n\n\n\n\n\n# Map of streets\np2<- ggplot() +\n  geom_sf(data = bronxdale, lwd = 0.5, color = \"black\", fill = tree_palette[\"fill_grey\"]) +\n  geom_sf(data = bbbb,\n          aes(color = tree_count),\n          lwd = 2.5) +\n  scale_color_gradient2(low = \"white\", \n                        mid = tree_palette[\"alive\"],\n                        high = tree_palette[\"dead\"], \n                       na.value = NA,\n                       name = \"Dead Trees Frequency\",\n                       breaks = c(0, 5, 10, 15, 20),\n                       limits = c(0,20)) +\n  labs(\n    title = stringr::str_wrap(\n      \"Streets in Bronxdale, Bronx that require the most street tree rehabilitation\")) +\n  theme_void() +\n  guides(color = guide_colorbar(barwidth = 20, barheight = 0.5, \n                                title.position = \"top\", title.hjust = 0.3,\n                                ticks = FALSE)) +\n  theme(plot.title = element_text(family = \"alegreya\", \n                                  size = 35, face = \"bold\",\n                                  margin = margin(b=15)),\n        legend.text = element_text(family = \"alegreya\",\n                                   size = 20),\n        legend.title = element_text(family = \"alegreya\",\n                                    size = 25, hjust = 0.8),\n        plot.title.position = \"plot\",\n        legend.position = \"top\") \n\np2"
  },
  {
    "objectID": "blog/2024-03-03-nyc-dead-trees/nyc-dead-trees.html#dead-trees-diameter-distribution",
    "href": "blog/2024-03-03-nyc-dead-trees/nyc-dead-trees.html#dead-trees-diameter-distribution",
    "title": "Visualizing NYC Dead Street Trees",
    "section": "Dead Trees Diameter Distribution",
    "text": "Dead Trees Diameter Distribution\nThe third question was answered by developing a visualization of tree trunk diameter for all reported dead trees is NYC. I initially graphed the distribution as a histogram to get a general idea of the distribution of the diameter. It was heavily skewed to the left with a majority of reported diameters being less than 10 inches. My approach was to set diameter ranges and determine how many trees fell within each range and then calculated the percent of trees in each range. Starting from 10, I increase in increments of 10 up to 40 inches. The idea behind this visualization was to make circles relative to the percentage of trees in the range. I wanted them to be circular to represent tree stumps and then through Canva I overlayed a tree ring design to each circle.\n\n\nCode\n# Analyzing the distribution of trunk diameter of dead trees ---\n\n# Filter to Dead and Stump classified trees \ndead_trees <- nyc_trees %>% \n  filter(status %in% c(\"Dead\",\"Stump\")) %>% \n  select(status, tree_dbh, stump_diam)\n\n# Set diameter of tree in a new column\nd <- dead_trees %>% \n  mutate(diam = ifelse(tree_dbh == 0, stump_diam, tree_dbh))\n\n# Drop geometry\nd1 <- d %>% select(diam) %>% \n  st_drop_geometry()\n\n# Set the breaks for the diameter ranges\ndiameters <- d1 %>% \n  filter(!is.na(diam)) %>%\n  mutate(range = cut(diam, breaks = c(0, 10, 20, 30, 40, Inf),\n                      labels = c(\"0 - 10 (in)\", \"10 - 20 (in)\", \"20 - 30 (in)\", \"30 - 40 (in)\", \"40 + (in)\"),\n                      include.lowest = TRUE)) %>% \n  group_by(range) %>% \n  summarise(count = n()) %>% \n  # determine percentage of dead trees in the selected ranges\n  mutate(total = nrow(d1),\n         percent = count/total) %>% \n  mutate(r = 10-(0.58706310 - percent)*10) %>% \n  # Set x and y positions for plotting\n  mutate(x0 = seq(-60, 40, length.out = 5),\n    y0 = 10)\n\n\n# Plotting\np3 <- ggplot(data = diameters) +\n  geom_circle(aes(x0 = x0, y0 = y0, r = r), fill = tree_palette[\"dead\"]) +\n  geom_text(aes(x = x0, y = y0, label = scales::percent(percent)),\n            color = \"white\", size = 4, fontface = \"bold\") +\n  geom_text(aes(x = x0, y = -3, label = range), color = \"black\", size = 3, fontface = \"bold\") +\n  theme(text = element_text(family = \"alegreya\")) +\n  theme_void() +\n  coord_fixed()\n\np3\n\n\n\n\n\nCode\n# Save plot\nggsave(\"plots/tree_diameter.png\", bg = \"transparent\",width = 15, height = 10)\n\n\nAbout 59% of the dead trees have a diameter between 0-10 inches. This is a bit concerning because this tells us younger trees are dying the most. They are not surviving past a certain age and this is something the NYC Parks and Recreation should consider investigating."
  },
  {
    "objectID": "blog/2024-03-03-nyc-dead-trees/nyc-dead-trees.html#design-elements",
    "href": "blog/2024-03-03-nyc-dead-trees/nyc-dead-trees.html#design-elements",
    "title": "Visualizing NYC Dead Street Trees",
    "section": "Design Elements",
    "text": "Design Elements\nThe design elements of this infographic were chosen carefully and took into consideration the following factors:\nText: The final graph, tree diameter, did not have a title coded in ggplot because I had difficulty getting it to align and be the right size. So I added the title for this graph in Canva. The captions and subtitles were also added through Canva as I found it difficult to align it how I would have liked in R.\nThemes: I removed grid lines and grid boxes for all of my the plots to have a simple clean background. I added a beige color background to the final infographic to contrast the green and brown in my color theme.\nColors: I created two palettes and are in the first code chunk in this blog post. I wanted to stick to a tree color theme and my main colors are brown and green. I stuck to colors within that range when creating the treemap. I wanted the emphasis to be solely on the dead tree section and not the different boroughs. Therefore I added the black box as a way to visually group the data by boroughs.\nTypography: For the text in the graph and infographic I used the font Alegreya, I though it was a nice font and it was one of the few I liked. I think it‚Äôs easy to read and understand and is not overly fancy or flamboyant. The text is Calibri Sans in the infographic.\nGeneral Design: The placement of my graphs in the visualization follow a see the big picture of all NYC trees and then zoom into a specific neighborhood. Then zoom back out to look at the diameter distribution. I also decided to add background information on how many trees and how the data was collected because I though it is what made the dataset unique. I also added text highlighting the major findings such as what was the total percent of dead trees. What borough saw the highest percent of dead trees and what was the value. This helped center and contextualize the data instead of just providing numbers.\nAccessibility: I added alt text to all my figures for readers that are visually impaired. For my color choice I picked shades of green and brown that were easy to distinguish and are colorblind-friendly.\nDEI lens: I think this is something I can further improve on now that I have identified what neighborhood has the highest percent of dead trees does this neighborhood have high population of low income? Can this be expressed across all neighborhoods does the median income relate to the number of dead trees?"
  }
]